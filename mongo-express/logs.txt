* 
* ==> Audit <==
* |--------------|------------------------|----------|---------------------|---------|---------------------|---------------------|
|   Command    |          Args          | Profile  |        User         | Version |     Start Time      |      End Time       |
|--------------|------------------------|----------|---------------------|---------|---------------------|---------------------|
| update-check |                        | minikube | Steve.X.Scammon.-ND | v1.28.0 | 18 Nov 22 13:12 EST | 18 Nov 22 13:12 EST |
| update-check |                        | minikube | Steve.X.Scammon.-ND | v1.28.0 | 12 Dec 22 15:13 EST | 12 Dec 22 15:13 EST |
| update-check |                        | minikube | Steve.X.Scammon.-ND | v1.28.0 | 23 Dec 22 14:20 EST | 23 Dec 22 14:20 EST |
| update-check |                        | minikube | Steve.X.Scammon.-ND | v1.28.0 | 03 Jan 23 11:33 EST | 03 Jan 23 11:33 EST |
| start        | --vm-driver=hyperkit   | minikube | Steve.X.Scammon.-ND | v1.28.0 | 11 Jan 23 12:54 EST |                     |
| start        | --vm-driver=qemu2      | minikube | Steve.X.Scammon.-ND | v1.28.0 | 11 Jan 23 12:55 EST |                     |
| start        |                        | minikube | Steve.X.Scammon.-ND | v1.28.0 | 11 Jan 23 13:12 EST |                     |
| start        | --vm-driver=qemu       | minikube | Steve.X.Scammon.-ND | v1.28.0 | 11 Jan 23 13:12 EST | 11 Jan 23 13:13 EST |
| update-check |                        | minikube | Steve.X.Scammon.-ND | v1.28.0 | 11 Jan 23 13:25 EST | 11 Jan 23 13:25 EST |
| service      | mongo-express-service  | minikube | Steve.X.Scammon.-ND | v1.28.0 | 11 Jan 23 14:40 EST |                     |
| stop         |                        | minikube | Steve.X.Scammon.-ND | v1.28.0 | 11 Jan 23 14:40 EST | 11 Jan 23 14:41 EST |
| start        | --network=socket_vmnet | minikube | Steve.X.Scammon.-ND | v1.28.0 | 11 Jan 23 14:41 EST |                     |
|--------------|------------------------|----------|---------------------|---------|---------------------|---------------------|

* 
* ==> Last Start <==
* Log file created at: 2023/01/11 14:41:18
Running on machine: K2M2HC957N
Binary: Built with gc go1.19.3 for darwin/arm64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0111 14:41:18.205144   77024 out.go:296] Setting OutFile to fd 1 ...
I0111 14:41:18.206050   77024 out.go:348] isatty.IsTerminal(1) = true
I0111 14:41:18.206053   77024 out.go:309] Setting ErrFile to fd 2...
I0111 14:41:18.206058   77024 out.go:348] isatty.IsTerminal(2) = true
I0111 14:41:18.206345   77024 root.go:334] Updating PATH: /Users/Steve.X.Scammon.-ND/.minikube/bin
W0111 14:41:18.206955   77024 root.go:311] Error reading config file at /Users/Steve.X.Scammon.-ND/.minikube/config/config.json: open /Users/Steve.X.Scammon.-ND/.minikube/config/config.json: no such file or directory
I0111 14:41:18.207971   77024 out.go:303] Setting JSON to false
I0111 14:41:18.249633   77024 start.go:116] hostinfo: {"hostname":"K2M2HC957N","uptime":170999,"bootTime":1673295079,"procs":534,"os":"darwin","platform":"darwin","platformFamily":"Standalone Workstation","platformVersion":"13.0","kernelVersion":"22.1.0","kernelArch":"arm64","virtualizationSystem":"","virtualizationRole":"","hostId":"095ee724-fe87-5080-8aed-a0729160e092"}
W0111 14:41:18.249724   77024 start.go:124] gopshost.Virtualization returned error: not implemented yet
I0111 14:41:18.256034   77024 out.go:177] üòÑ  minikube v1.28.0 on Darwin 13.0 (arm64)
I0111 14:41:18.269786   77024 notify.go:220] Checking for updates...
I0111 14:41:18.270006   77024 config.go:180] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.25.3
I0111 14:41:18.270670   77024 driver.go:365] Setting default libvirt URI to qemu:///system
I0111 14:41:18.280062   77024 out.go:177] ‚ú®  Using the qemu2 (experimental) driver based on existing profile
I0111 14:41:18.288027   77024 start.go:282] selected driver: qemu2
I0111 14:41:18.288047   77024 start.go:808] validating driver "qemu2" against &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.28.0-arm64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.36@sha256:8debc1b6a335075c5f99bfbf131b4f5566f68c6500dc5991817832e55fcc9456 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:57698 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.25.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.25.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:user Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath:/opt/socket_vmnet/bin/socket_vmnet_client SocketVMnetPath:/var/run/socket_vmnet}
I0111 14:41:18.288124   77024 start.go:819] status for qemu2: {Installed:true Healthy:true Running:true NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0111 14:41:18.288343   77024 cni.go:95] Creating CNI manager for ""
I0111 14:41:18.288363   77024 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0111 14:41:18.288383   77024 start_flags.go:317] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.28.0-arm64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.36@sha256:8debc1b6a335075c5f99bfbf131b4f5566f68c6500dc5991817832e55fcc9456 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:57698 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.25.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.25.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:socket_vmnet Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath:/opt/socket_vmnet/bin/socket_vmnet_client SocketVMnetPath:/var/run/socket_vmnet}
I0111 14:41:18.288981   77024 iso.go:124] acquiring lock: {Name:mk6d7058f1e3e8121a489747fa3337acdc92dd19 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0111 14:41:18.300024   77024 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I0111 14:41:18.303090   77024 preload.go:132] Checking if preload exists for k8s version v1.25.3 and runtime docker
I0111 14:41:18.303132   77024 preload.go:148] Found local preload: /Users/Steve.X.Scammon.-ND/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.25.3-docker-overlay2-arm64.tar.lz4
I0111 14:41:18.303189   77024 cache.go:57] Caching tarball of preloaded images
I0111 14:41:18.311086   77024 preload.go:174] Found /Users/Steve.X.Scammon.-ND/.minikube/cache/preloaded-tarball/preloaded-images-k8s-v18-v1.25.3-docker-overlay2-arm64.tar.lz4 in cache, skipping download
I0111 14:41:18.311106   77024 cache.go:60] Finished verifying existence of preloaded tar for  v1.25.3 on docker
I0111 14:41:18.311187   77024 profile.go:148] Saving config to /Users/Steve.X.Scammon.-ND/.minikube/profiles/minikube/config.json ...
I0111 14:41:18.313486   77024 cache.go:208] Successfully downloaded all kic artifacts
I0111 14:41:18.313523   77024 start.go:364] acquiring machines lock for minikube: {Name:mk6e6877f2e5c69b58a4ac7cb56ccadb07353659 Clock:{} Delay:500ms Timeout:13m0s Cancel:<nil>}
I0111 14:41:18.313711   77024 start.go:368] acquired machines lock for "minikube" in 180.917¬µs
I0111 14:41:18.313736   77024 start.go:96] Skipping create...Using existing machine configuration
I0111 14:41:18.313739   77024 fix.go:55] fixHost starting: 
I0111 14:41:18.314025   77024 fix.go:103] recreateIfNeeded on minikube: state=Stopped err=<nil>
W0111 14:41:18.314030   77024 fix.go:129] unexpected machine state, will restart: <nil>
I0111 14:41:18.321851   77024 out.go:177] üîÑ  Restarting existing qemu2 VM for "minikube" ...
I0111 14:41:18.326181   77024 main.go:134] libmachine: executing: qemu-system-aarch64 -M virt -cpu host -drive file=/opt/homebrew/Cellar/qemu/7.2.0/share/qemu/edk2-aarch64-code.fd,readonly=on,format=raw,if=pflash -display none -accel hvf -m 4000 -smp 2 -boot d -cdrom /Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/boot2docker.iso -qmp unix:/Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/monitor,server,nowait -pidfile /Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/qemu.pid -nic user,model=virtio,hostfwd=tcp::57661-:22,hostfwd=tcp::57662-:2376,hostname=minikube -daemonize /Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/disk.qcow2
I0111 14:41:18.476359   77024 main.go:134] libmachine: STDOUT: 
I0111 14:41:18.476376   77024 main.go:134] libmachine: STDERR: 
I0111 14:41:18.476381   77024 main.go:134] libmachine: Waiting for VM to start (ssh -p 57661 docker@127.0.0.1)...
I0111 14:41:39.144455   77024 profile.go:148] Saving config to /Users/Steve.X.Scammon.-ND/.minikube/profiles/minikube/config.json ...
I0111 14:41:39.147428   77024 machine.go:88] provisioning docker machine ...
I0111 14:41:39.148404   77024 buildroot.go:166] provisioning hostname "minikube"
I0111 14:41:39.148900   77024 main.go:134] libmachine: Using SSH client type: native
I0111 14:41:39.150338   77024 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x1048f8a30] 0x1048fb4d0 <nil>  [] 0s} localhost 57661 <nil> <nil>}
I0111 14:41:39.150348   77024 main.go:134] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0111 14:41:39.221259   77024 main.go:134] libmachine: SSH cmd err, output: <nil>: minikube

I0111 14:41:39.221400   77024 main.go:134] libmachine: Using SSH client type: native
I0111 14:41:39.222841   77024 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x1048f8a30] 0x1048fb4d0 <nil>  [] 0s} localhost 57661 <nil> <nil>}
I0111 14:41:39.222850   77024 main.go:134] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0111 14:41:39.278207   77024 main.go:134] libmachine: SSH cmd err, output: <nil>: 
I0111 14:41:39.278216   77024 buildroot.go:172] set auth options {CertDir:/Users/Steve.X.Scammon.-ND/.minikube CaCertPath:/Users/Steve.X.Scammon.-ND/.minikube/certs/ca.pem CaPrivateKeyPath:/Users/Steve.X.Scammon.-ND/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/Users/Steve.X.Scammon.-ND/.minikube/machines/server.pem ServerKeyPath:/Users/Steve.X.Scammon.-ND/.minikube/machines/server-key.pem ClientKeyPath:/Users/Steve.X.Scammon.-ND/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/Users/Steve.X.Scammon.-ND/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/Users/Steve.X.Scammon.-ND/.minikube}
I0111 14:41:39.278234   77024 buildroot.go:174] setting up certificates
I0111 14:41:39.279353   77024 provision.go:83] configureAuth start
I0111 14:41:39.279358   77024 provision.go:138] copyHostCerts
I0111 14:41:39.280463   77024 exec_runner.go:144] found /Users/Steve.X.Scammon.-ND/.minikube/ca.pem, removing ...
I0111 14:41:39.280817   77024 exec_runner.go:207] rm: /Users/Steve.X.Scammon.-ND/.minikube/ca.pem
I0111 14:41:39.282200   77024 exec_runner.go:151] cp: /Users/Steve.X.Scammon.-ND/.minikube/certs/ca.pem --> /Users/Steve.X.Scammon.-ND/.minikube/ca.pem (1111 bytes)
I0111 14:41:39.283227   77024 exec_runner.go:144] found /Users/Steve.X.Scammon.-ND/.minikube/cert.pem, removing ...
I0111 14:41:39.283229   77024 exec_runner.go:207] rm: /Users/Steve.X.Scammon.-ND/.minikube/cert.pem
I0111 14:41:39.283620   77024 exec_runner.go:151] cp: /Users/Steve.X.Scammon.-ND/.minikube/certs/cert.pem --> /Users/Steve.X.Scammon.-ND/.minikube/cert.pem (1155 bytes)
I0111 14:41:39.284551   77024 exec_runner.go:144] found /Users/Steve.X.Scammon.-ND/.minikube/key.pem, removing ...
I0111 14:41:39.284553   77024 exec_runner.go:207] rm: /Users/Steve.X.Scammon.-ND/.minikube/key.pem
I0111 14:41:39.286140   77024 exec_runner.go:151] cp: /Users/Steve.X.Scammon.-ND/.minikube/certs/key.pem --> /Users/Steve.X.Scammon.-ND/.minikube/key.pem (1679 bytes)
I0111 14:41:39.286417   77024 provision.go:112] generating server cert: /Users/Steve.X.Scammon.-ND/.minikube/machines/server.pem ca-key=/Users/Steve.X.Scammon.-ND/.minikube/certs/ca.pem private-key=/Users/Steve.X.Scammon.-ND/.minikube/certs/ca-key.pem org=Steve.X.Scammon.-ND.minikube san=[127.0.0.1 localhost localhost 127.0.0.1 minikube minikube]
I0111 14:41:39.355902   77024 provision.go:172] copyRemoteCerts
I0111 14:41:39.356701   77024 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0111 14:41:39.356712   77024 sshutil.go:53] new ssh client: &{IP:localhost Port:57661 SSHKeyPath:/Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/id_rsa Username:docker}
I0111 14:41:39.384620   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/machines/server.pem --> /etc/docker/server.pem (1245 bytes)
I0111 14:41:39.392311   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/machines/server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0111 14:41:39.399951   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/certs/ca.pem --> /etc/docker/ca.pem (1111 bytes)
I0111 14:41:39.407358   77024 provision.go:86] duration metric: configureAuth took 127.998334ms
I0111 14:41:39.407365   77024 buildroot.go:189] setting minikube options for container-runtime
I0111 14:41:39.407722   77024 config.go:180] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.25.3
I0111 14:41:39.407825   77024 main.go:134] libmachine: Using SSH client type: native
I0111 14:41:39.408017   77024 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x1048f8a30] 0x1048fb4d0 <nil>  [] 0s} localhost 57661 <nil> <nil>}
I0111 14:41:39.408026   77024 main.go:134] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0111 14:41:39.457473   77024 main.go:134] libmachine: SSH cmd err, output: <nil>: tmpfs

I0111 14:41:39.457478   77024 buildroot.go:70] root file system type: tmpfs
I0111 14:41:39.457607   77024 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0111 14:41:39.457717   77024 main.go:134] libmachine: Using SSH client type: native
I0111 14:41:39.458103   77024 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x1048f8a30] 0x1048fb4d0 <nil>  [] 0s} localhost 57661 <nil> <nil>}
I0111 14:41:39.458134   77024 main.go:134] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=qemu2 --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0111 14:41:39.511098   77024 main.go:134] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
After=network.target  minikube-automount.service docker.socket
Requires= minikube-automount.service docker.socket 
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=qemu2 --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0111 14:41:39.512171   77024 main.go:134] libmachine: Using SSH client type: native
I0111 14:41:39.512727   77024 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x1048f8a30] 0x1048fb4d0 <nil>  [] 0s} localhost 57661 <nil> <nil>}
I0111 14:41:39.512734   77024 main.go:134] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0111 14:41:39.984210   77024 main.go:134] libmachine: SSH cmd err, output: <nil>: diff: can't stat '/lib/systemd/system/docker.service': No such file or directory
Created symlink /etc/systemd/system/multi-user.target.wants/docker.service ‚Üí /usr/lib/systemd/system/docker.service.

I0111 14:41:39.984221   77024 machine.go:91] provisioned docker machine in 836.784958ms
I0111 14:41:39.984226   77024 start.go:300] post-start starting for "minikube" (driver="qemu2")
I0111 14:41:39.984229   77024 start.go:328] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0111 14:41:39.984339   77024 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0111 14:41:39.984346   77024 sshutil.go:53] new ssh client: &{IP:localhost Port:57661 SSHKeyPath:/Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/id_rsa Username:docker}
I0111 14:41:40.016915   77024 ssh_runner.go:195] Run: cat /etc/os-release
I0111 14:41:40.018247   77024 info.go:137] Remote host: Buildroot 2021.02.12
I0111 14:41:40.018253   77024 filesync.go:126] Scanning /Users/Steve.X.Scammon.-ND/.minikube/addons for local assets ...
I0111 14:41:40.018721   77024 filesync.go:126] Scanning /Users/Steve.X.Scammon.-ND/.minikube/files for local assets ...
I0111 14:41:40.019020   77024 start.go:303] post-start completed in 34.791333ms
I0111 14:41:40.019023   77024 fix.go:57] fixHost completed within 21.7052255s
I0111 14:41:40.019114   77024 main.go:134] libmachine: Using SSH client type: native
I0111 14:41:40.019369   77024 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x1048f8a30] 0x1048fb4d0 <nil>  [] 0s} localhost 57661 <nil> <nil>}
I0111 14:41:40.019372   77024 main.go:134] libmachine: About to run SSH command:
date +%!s(MISSING).%!N(MISSING)
I0111 14:41:40.069775   77024 main.go:134] libmachine: SSH cmd err, output: <nil>: 1673466099.819193088

I0111 14:41:40.069779   77024 fix.go:207] guest clock: 1673466099.819193088
I0111 14:41:40.069787   77024 fix.go:220] Guest: 2023-01-11 14:41:39.819193088 -0500 EST Remote: 2023-01-11 14:41:40.019026 -0500 EST m=+21.923306626 (delta=-199.832912ms)
I0111 14:41:40.069797   77024 fix.go:191] guest clock delta is within tolerance: -199.832912ms
I0111 14:41:40.069800   77024 start.go:83] releasing machines lock for "minikube", held for 21.756025625s
I0111 14:41:40.072302   77024 ssh_runner.go:195] Run: systemctl --version
I0111 14:41:40.072314   77024 sshutil.go:53] new ssh client: &{IP:localhost Port:57661 SSHKeyPath:/Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/id_rsa Username:docker}
I0111 14:41:40.072583   77024 ssh_runner.go:195] Run: curl -sS -m 2 https://registry.k8s.io/
I0111 14:41:40.072954   77024 sshutil.go:53] new ssh client: &{IP:localhost Port:57661 SSHKeyPath:/Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/id_rsa Username:docker}
I0111 14:41:40.100673   77024 preload.go:132] Checking if preload exists for k8s version v1.25.3 and runtime docker
I0111 14:41:40.100820   77024 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0111 14:41:40.278056   77024 docker.go:613] Got preloaded images: -- stdout --
nginx:latest
mongo:latest
mongo-express:latest
registry.k8s.io/kube-apiserver:v1.25.3
registry.k8s.io/kube-proxy:v1.25.3
registry.k8s.io/kube-controller-manager:v1.25.3
registry.k8s.io/kube-scheduler:v1.25.3
registry.k8s.io/pause:3.8
registry.k8s.io/etcd:3.5.4-0
registry.k8s.io/coredns/coredns:v1.9.3
k8s.gcr.io/pause:3.6
gcr.io/k8s-minikube/storage-provisioner:v5
nginx:1.16

-- /stdout --
I0111 14:41:40.278327   77024 docker.go:543] Images already preloaded, skipping extraction
I0111 14:41:40.278647   77024 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0111 14:41:40.289269   77024 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service containerd
I0111 14:41:40.297372   77024 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0111 14:41:40.303980   77024 ssh_runner.go:195] Run: sudo systemctl stop -f crio
I0111 14:41:40.353306   77024 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0111 14:41:40.360299   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
image-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0111 14:41:40.366914   77024 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0111 14:41:40.437335   77024 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0111 14:41:40.520868   77024 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0111 14:41:40.594914   77024 ssh_runner.go:195] Run: sudo systemctl restart docker
I0111 14:41:41.795783   77024 ssh_runner.go:235] Completed: sudo systemctl restart docker: (1.20085175s)
I0111 14:41:41.795905   77024 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0111 14:41:41.877676   77024 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0111 14:41:41.960481   77024 ssh_runner.go:195] Run: sudo systemctl start cri-docker.socket
I0111 14:41:41.968405   77024 start.go:451] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0111 14:41:41.969907   77024 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0111 14:41:41.972447   77024 start.go:472] Will wait 60s for crictl version
I0111 14:41:41.972514   77024 ssh_runner.go:195] Run: sudo crictl version
I0111 14:41:42.029691   77024 start.go:481] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  20.10.20
RuntimeApiVersion:  1.41.0
I0111 14:41:42.029811   77024 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0111 14:41:42.040304   77024 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0111 14:41:42.058075   77024 out.go:204] üê≥  Preparing Kubernetes v1.25.3 on Docker 20.10.20 ...
I0111 14:41:42.058935   77024 ssh_runner.go:195] Run: grep 10.0.2.2	host.minikube.internal$ /etc/hosts
I0111 14:41:42.060749   77024 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "10.0.2.2	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0111 14:41:42.065370   77024 preload.go:132] Checking if preload exists for k8s version v1.25.3 and runtime docker
I0111 14:41:42.065438   77024 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0111 14:41:42.074213   77024 docker.go:613] Got preloaded images: -- stdout --
nginx:latest
mongo:latest
mongo-express:latest
registry.k8s.io/kube-apiserver:v1.25.3
registry.k8s.io/kube-proxy:v1.25.3
registry.k8s.io/kube-scheduler:v1.25.3
registry.k8s.io/kube-controller-manager:v1.25.3
registry.k8s.io/pause:3.8
registry.k8s.io/etcd:3.5.4-0
registry.k8s.io/coredns/coredns:v1.9.3
k8s.gcr.io/pause:3.6
gcr.io/k8s-minikube/storage-provisioner:v5
nginx:1.16

-- /stdout --
I0111 14:41:42.074219   77024 docker.go:543] Images already preloaded, skipping extraction
I0111 14:41:42.074591   77024 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0111 14:41:42.083361   77024 docker.go:613] Got preloaded images: -- stdout --
nginx:latest
mongo:latest
mongo-express:latest
registry.k8s.io/kube-apiserver:v1.25.3
registry.k8s.io/kube-controller-manager:v1.25.3
registry.k8s.io/kube-scheduler:v1.25.3
registry.k8s.io/kube-proxy:v1.25.3
registry.k8s.io/pause:3.8
registry.k8s.io/etcd:3.5.4-0
registry.k8s.io/coredns/coredns:v1.9.3
k8s.gcr.io/pause:3.6
gcr.io/k8s-minikube/storage-provisioner:v5
nginx:1.16

-- /stdout --
I0111 14:41:42.083368   77024 cache_images.go:84] Images are preloaded, skipping loading
I0111 14:41:42.083558   77024 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0111 14:41:42.094201   77024 cni.go:95] Creating CNI manager for ""
I0111 14:41:42.094207   77024 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0111 14:41:42.094455   77024 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0111 14:41:42.094471   77024 kubeadm.go:156] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:10.0.2.15 APIServerPort:8443 KubernetesVersion:v1.25.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "10.0.2.15"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NodeIP:10.0.2.15 CgroupDriver:systemd ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[] ResolvConfSearchRegression:false}
I0111 14:41:42.094570   77024 kubeadm.go:161] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 10.0.2.15
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 10.0.2.15
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "10.0.2.15"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.25.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: systemd
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0111 14:41:42.094801   77024 kubeadm.go:962] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.25.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=/var/run/cri-dockerd.sock --hostname-override=minikube --image-service-endpoint=/var/run/cri-dockerd.sock --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=10.0.2.15 --runtime-request-timeout=15m

[Install]
 config:
{KubernetesVersion:v1.25.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0111 14:41:42.094899   77024 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.25.3
I0111 14:41:42.098575   77024 binaries.go:44] Found k8s binaries, skipping transfer
I0111 14:41:42.098643   77024 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0111 14:41:42.101298   77024 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (467 bytes)
I0111 14:41:42.106534   77024 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0111 14:41:42.112132   77024 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2021 bytes)
I0111 14:41:42.118455   77024 ssh_runner.go:195] Run: grep 10.0.2.15	control-plane.minikube.internal$ /etc/hosts
I0111 14:41:42.119891   77024 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "10.0.2.15	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0111 14:41:42.123637   77024 certs.go:54] Setting up /Users/Steve.X.Scammon.-ND/.minikube/profiles/minikube for IP: 10.0.2.15
I0111 14:41:42.124360   77024 certs.go:182] skipping minikubeCA CA generation: /Users/Steve.X.Scammon.-ND/.minikube/ca.key
I0111 14:41:42.126064   77024 certs.go:182] skipping proxyClientCA CA generation: /Users/Steve.X.Scammon.-ND/.minikube/proxy-client-ca.key
I0111 14:41:42.126613   77024 certs.go:298] skipping minikube-user signed cert generation: /Users/Steve.X.Scammon.-ND/.minikube/profiles/minikube/client.key
I0111 14:41:42.127263   77024 certs.go:298] skipping minikube signed cert generation: /Users/Steve.X.Scammon.-ND/.minikube/profiles/minikube/apiserver.key.49504c3e
I0111 14:41:42.127722   77024 certs.go:298] skipping aggregator signed cert generation: /Users/Steve.X.Scammon.-ND/.minikube/profiles/minikube/proxy-client.key
I0111 14:41:42.129659   77024 certs.go:388] found cert: /Users/Steve.X.Scammon.-ND/.minikube/certs/Users/Steve.X.Scammon.-ND/.minikube/certs/ca-key.pem (1675 bytes)
I0111 14:41:42.129885   77024 certs.go:388] found cert: /Users/Steve.X.Scammon.-ND/.minikube/certs/Users/Steve.X.Scammon.-ND/.minikube/certs/ca.pem (1111 bytes)
I0111 14:41:42.130047   77024 certs.go:388] found cert: /Users/Steve.X.Scammon.-ND/.minikube/certs/Users/Steve.X.Scammon.-ND/.minikube/certs/cert.pem (1155 bytes)
I0111 14:41:42.130205   77024 certs.go:388] found cert: /Users/Steve.X.Scammon.-ND/.minikube/certs/Users/Steve.X.Scammon.-ND/.minikube/certs/key.pem (1679 bytes)
I0111 14:41:42.133417   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/profiles/minikube/apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0111 14:41:42.142234   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/profiles/minikube/apiserver.key --> /var/lib/minikube/certs/apiserver.key (1679 bytes)
I0111 14:41:42.149546   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/profiles/minikube/proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0111 14:41:42.157542   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/profiles/minikube/proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I0111 14:41:42.165585   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0111 14:41:42.172888   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/ca.key --> /var/lib/minikube/certs/ca.key (1675 bytes)
I0111 14:41:42.180774   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0111 14:41:42.189032   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0111 14:41:42.197665   77024 ssh_runner.go:362] scp /Users/Steve.X.Scammon.-ND/.minikube/ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0111 14:41:42.205462   77024 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0111 14:41:42.211550   77024 ssh_runner.go:195] Run: openssl version
I0111 14:41:42.213497   77024 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0111 14:41:42.217046   77024 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0111 14:41:42.218370   77024 certs.go:431] hashing: -rw-r--r-- 1 root root 1111 Jan 11 18:13 /usr/share/ca-certificates/minikubeCA.pem
I0111 14:41:42.218419   77024 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0111 14:41:42.220356   77024 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0111 14:41:42.224246   77024 kubeadm.go:396] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.28.0-arm64.iso KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.36@sha256:8debc1b6a335075c5f99bfbf131b4f5566f68c6500dc5991817832e55fcc9456 Memory:4000 CPUs:2 DiskSize:20000 VMDriver: Driver:qemu2 HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:57698 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.25.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.25.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[default-storageclass:true storage-provisioner:true] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network:socket_vmnet Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:/Users:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath: SocketVMnetClientPath:/opt/socket_vmnet/bin/socket_vmnet_client SocketVMnetPath:/var/run/socket_vmnet}
I0111 14:41:42.224360   77024 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0111 14:41:42.233267   77024 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0111 14:41:42.237783   77024 host.go:66] Checking if "minikube" exists ...
I0111 14:41:42.240305   77024 main.go:134] libmachine: Using SSH client type: external
I0111 14:41:42.240329   77024 main.go:134] libmachine: Using SSH private key: /Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/id_rsa (-rw-------)
I0111 14:41:42.240345   77024 main.go:134] libmachine: &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/id_rsa -p 57661] /usr/bin/ssh <nil>}
I0111 14:41:42.240359   77024 main.go:134] libmachine: /usr/bin/ssh -F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/id_rsa -p 57661 -f -NTL 57698:localhost:8443
I0111 14:41:42.343599   77024 kubeadm.go:411] found existing configuration files, will attempt cluster restart
I0111 14:41:42.343639   77024 kubeadm.go:627] restartCluster start
I0111 14:41:42.343775   77024 ssh_runner.go:195] Run: sudo test -d /data/minikube
I0111 14:41:42.347571   77024 kubeadm.go:127] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
stdout:

stderr:
I0111 14:41:42.349251   77024 kubeconfig.go:135] verify returned: extract IP: "minikube" does not appear in /Users/Steve.X.Scammon.-ND/.kube/config
I0111 14:41:42.349463   77024 kubeconfig.go:146] "minikube" context is missing from /Users/Steve.X.Scammon.-ND/.kube/config - will repair!
I0111 14:41:42.349651   77024 lock.go:35] WriteFile acquiring /Users/Steve.X.Scammon.-ND/.kube/config: {Name:mk12d40ff906dba732924b914132b1a882ee2bc5 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0111 14:41:42.360076   77024 ssh_runner.go:195] Run: sudo diff -u /var/tmp/minikube/kubeadm.yaml /var/tmp/minikube/kubeadm.yaml.new
I0111 14:41:42.363749   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:42.363833   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:42.367288   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:42.567948   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:42.568114   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:42.572847   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:42.767789   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:42.768121   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:42.776595   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:42.967573   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:42.967903   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:42.977884   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:43.167933   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:43.168243   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:43.178071   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:43.368417   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:43.368634   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:43.376539   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:43.568402   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:43.568621   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:43.589203   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:43.768076   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:43.768499   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:43.805926   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:43.968199   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:43.968338   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:43.974867   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:44.168460   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:44.169002   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:44.199588   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:44.367613   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:44.368356   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:44.395572   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:44.570063   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:44.570687   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:44.582262   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:44.767748   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:44.768172   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:44.793367   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:44.968282   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:44.968885   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:45.016355   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:45.168350   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:45.168505   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:45.174311   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:45.368566   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:45.368959   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:45.387340   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:45.387347   77024 api_server.go:165] Checking apiserver status ...
I0111 14:41:45.387484   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
W0111 14:41:45.393546   77024 api_server.go:169] stopped: unable to get apiserver pid: sudo pgrep -xnf kube-apiserver.*minikube.*: Process exited with status 1
stdout:

stderr:
I0111 14:41:45.393560   77024 kubeadm.go:602] needs reconfigure: apiserver error: timed out waiting for the condition
I0111 14:41:45.393575   77024 kubeadm.go:1114] stopping kube-system containers ...
I0111 14:41:45.393685   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0111 14:41:45.408641   77024 docker.go:444] Stopping containers: [b4939274fa91 1cae9edf95e2 6782b13ceb31 3c9b4140198c 2aeeb88e9374 12a7db6950d3 3c6a8e6f9155 3bce5f4dbff8 61e2086ff549 b6d7276c92d6 b63f8228998e 8e3f6473f3b1 563d1bc47ea1 d73adccf50b9]
I0111 14:41:45.408756   77024 ssh_runner.go:195] Run: docker stop b4939274fa91 1cae9edf95e2 6782b13ceb31 3c9b4140198c 2aeeb88e9374 12a7db6950d3 3c6a8e6f9155 3bce5f4dbff8 61e2086ff549 b6d7276c92d6 b63f8228998e 8e3f6473f3b1 563d1bc47ea1 d73adccf50b9
I0111 14:41:45.422860   77024 ssh_runner.go:195] Run: sudo systemctl stop kubelet
I0111 14:41:45.433208   77024 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0111 14:41:45.437759   77024 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0111 14:41:45.437853   77024 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0111 14:41:45.441891   77024 kubeadm.go:704] reconfiguring cluster from /var/tmp/minikube/kubeadm.yaml
I0111 14:41:45.441897   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
I0111 14:41:45.536853   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase kubeconfig all --config /var/tmp/minikube/kubeadm.yaml"
I0111 14:41:46.091599   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase kubelet-start --config /var/tmp/minikube/kubeadm.yaml"
I0111 14:41:46.198704   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase control-plane all --config /var/tmp/minikube/kubeadm.yaml"
I0111 14:41:46.223725   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init phase etcd local --config /var/tmp/minikube/kubeadm.yaml"
I0111 14:41:46.245358   77024 api_server.go:51] waiting for apiserver process to appear ...
I0111 14:41:46.245479   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0111 14:41:46.750963   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0111 14:41:47.251770   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0111 14:41:47.751792   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0111 14:41:47.772843   77024 api_server.go:71] duration metric: took 1.527495083s to wait for apiserver process to appear ...
I0111 14:41:47.772894   77024 api_server.go:87] waiting for apiserver healthz status ...
I0111 14:41:47.772902   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:41:52.774921   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:41:53.276025   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:41:58.277018   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:41:58.776071   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:42:03.780810   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:42:04.287662   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:42:09.300136   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:42:09.776142   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:42:14.778166   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:42:14.778234   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:42:19.781749   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:42:20.276109   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:42:25.276554   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:42:25.777398   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:42:30.810142   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:42:31.276170   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:42:36.315138   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:42:36.778006   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:42:41.909077   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:42:42.276209   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:42:47.277266   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:42:47.780883   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:42:47.828258   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:42:47.828377   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:42:47.839011   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:42:47.839123   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:42:47.848665   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:42:47.848803   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:42:47.857210   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:42:47.857305   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:42:47.865781   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:42:47.865963   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:42:47.888987   77024 logs.go:274] 0 containers: []
W0111 14:42:47.888994   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:42:47.889085   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:42:47.898070   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:42:47.898192   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:42:47.907879   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:42:47.909233   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:42:47.909253   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:42:47.930586   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:42:47.930594   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:42:47.941184   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:42:47.941190   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:42:47.949919   77024 logs.go:123] Gathering logs for container status ...
I0111 14:42:47.949926   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:42:47.970649   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:42:47.970657   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:42:47.980886   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:42:47.980893   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:42:47.990283   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:42:47.990289   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:42:48.009526   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:42:48.009533   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:42:48.026865   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:42:48.026874   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:42:48.038341   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:42:48.038349   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:42:48.054085   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:42:48.054093   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:42:48.065563   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:42:48.065570   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:42:48.275817   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:42:48.275826   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:42:48.320858   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:42:48.320868   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:42:48.351771   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:42:48.351787   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:42:48.371250   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:42:48.371259   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:42:48.375999   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:42:48.376003   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:42:48.387499   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:42:48.387506   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:42:48.403552   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:42:48.403561   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:42:50.914268   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:42:55.915833   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:42:56.275986   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:42:56.299503   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:42:56.299649   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:42:56.313826   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:42:56.313951   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:42:56.325997   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:42:56.326110   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:42:56.336244   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:42:56.336341   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:42:56.345765   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:42:56.345853   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:42:56.353780   77024 logs.go:274] 0 containers: []
W0111 14:42:56.353786   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:42:56.353883   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:42:56.363837   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:42:56.363945   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:42:56.373028   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:42:56.373039   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:42:56.373042   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:42:56.383139   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:42:56.383148   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:42:56.391998   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:42:56.392003   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:42:56.403288   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:42:56.403296   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:42:56.418086   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:42:56.418094   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:42:56.473867   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:42:56.473875   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:42:56.484703   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:42:56.484716   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:42:56.498835   77024 logs.go:123] Gathering logs for container status ...
I0111 14:42:56.498853   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:42:56.517699   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:42:56.517705   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:42:56.532319   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:42:56.532327   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:42:56.548738   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:42:56.548745   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:42:56.564971   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:42:56.564981   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:42:56.576708   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:42:56.576717   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:42:56.588214   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:42:56.588219   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:42:56.599836   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:42:56.599863   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:42:56.610484   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:42:56.610496   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:42:56.630276   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:42:56.630286   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:42:56.648393   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:42:56.648408   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:42:56.653954   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:42:56.653960   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:42:59.174452   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:43:04.176275   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:43:04.276249   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:43:04.301111   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:43:04.301246   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:43:04.316009   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:43:04.316131   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:43:04.331480   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:43:04.331620   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:43:04.342917   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:43:04.343015   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:43:04.351961   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:43:04.352055   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:43:04.360823   77024 logs.go:274] 0 containers: []
W0111 14:43:04.360830   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:43:04.360917   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:43:04.369297   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:43:04.369401   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:43:04.378151   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:43:04.378163   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:43:04.378168   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:43:04.383647   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:43:04.383652   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:43:04.396575   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:43:04.396588   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:43:04.406097   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:43:04.406106   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:43:04.421602   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:43:04.421610   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:43:04.440536   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:43:04.440544   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:43:04.457026   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:43:04.457035   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:43:04.473680   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:43:04.473694   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:43:04.484524   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:43:04.484536   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:43:04.494256   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:43:04.494265   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:43:04.538264   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:43:04.538273   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:43:04.549742   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:43:04.549747   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:43:04.558539   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:43:04.558544   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:43:04.567209   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:43:04.567215   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:43:04.575350   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:43:04.575357   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:43:04.587123   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:43:04.587130   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:43:04.597019   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:43:04.597025   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:43:04.613212   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:43:04.613219   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:43:04.633217   77024 logs.go:123] Gathering logs for container status ...
I0111 14:43:04.633225   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:43:07.150628   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:43:12.153287   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:43:12.276427   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:43:12.297658   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:43:12.297768   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:43:12.308279   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:43:12.308388   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:43:12.317678   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:43:12.317779   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:43:12.327219   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:43:12.327324   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:43:12.337142   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:43:12.337241   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:43:12.345466   77024 logs.go:274] 0 containers: []
W0111 14:43:12.345473   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:43:12.345558   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:43:12.353341   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:43:12.353433   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:43:12.361696   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:43:12.361708   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:43:12.361712   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:43:12.366620   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:43:12.366624   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:43:12.378874   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:43:12.378882   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:43:12.393943   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:43:12.393951   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:43:12.402669   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:43:12.402676   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:43:12.416266   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:43:12.416273   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:43:12.428405   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:43:12.428413   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:43:12.443832   77024 logs.go:123] Gathering logs for container status ...
I0111 14:43:12.443841   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:43:12.459740   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:43:12.459749   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:43:12.476790   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:43:12.476800   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:43:12.519996   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:43:12.520004   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:43:12.536668   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:43:12.536676   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:43:12.545827   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:43:12.545835   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:43:12.554598   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:43:12.554607   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:43:12.562910   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:43:12.562915   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:43:12.573583   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:43:12.573590   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:43:12.590704   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:43:12.590711   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:43:12.610080   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:43:12.610089   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:43:12.620092   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:43:12.620101   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:43:15.130365   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:43:20.132265   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:43:20.278508   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:43:20.297361   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:43:20.297494   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:43:20.311597   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:43:20.311714   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:43:20.323671   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:43:20.323799   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:43:20.333646   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:43:20.333740   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:43:20.344686   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:43:20.344781   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:43:20.353044   77024 logs.go:274] 0 containers: []
W0111 14:43:20.353049   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:43:20.353118   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:43:20.365012   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:43:20.365103   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:43:20.372953   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:43:20.372964   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:43:20.372968   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:43:20.389272   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:43:20.389279   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:43:20.408975   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:43:20.408981   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:43:20.417451   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:43:20.417457   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:43:20.426514   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:43:20.426522   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:43:20.439451   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:43:20.439459   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:43:20.448545   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:43:20.448552   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:43:20.457499   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:43:20.457505   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:43:20.472409   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:43:20.472415   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:43:20.486414   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:43:20.486421   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:43:20.499066   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:43:20.499073   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:43:20.511646   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:43:20.511654   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:43:20.516199   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:43:20.516204   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:43:20.558311   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:43:20.558319   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:43:20.569687   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:43:20.569693   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:43:20.578128   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:43:20.578133   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:43:20.586228   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:43:20.586234   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:43:20.600329   77024 logs.go:123] Gathering logs for container status ...
I0111 14:43:20.600341   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:43:20.614056   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:43:20.614063   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:43:23.133506   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:43:28.139169   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:43:28.278824   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:43:28.306692   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:43:28.306845   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:43:28.323837   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:43:28.323955   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:43:28.334098   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:43:28.334204   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:43:28.343455   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:43:28.343546   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:43:28.352912   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:43:28.353011   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:43:28.360999   77024 logs.go:274] 0 containers: []
W0111 14:43:28.361005   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:43:28.361087   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:43:28.369043   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:43:28.369127   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:43:28.378590   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:43:28.378601   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:43:28.378606   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:43:28.383497   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:43:28.383502   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:43:28.427430   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:43:28.427439   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:43:28.440339   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:43:28.440347   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:43:28.456764   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:43:28.456769   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:43:28.471859   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:43:28.471862   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:43:28.483211   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:43:28.483219   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:43:28.493465   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:43:28.493473   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:43:28.509498   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:43:28.509504   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:43:28.520590   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:43:28.520597   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:43:28.531157   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:43:28.531163   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:43:28.552102   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:43:28.552109   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:43:28.567913   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:43:28.567921   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:43:28.585681   77024 logs.go:123] Gathering logs for container status ...
I0111 14:43:28.585688   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:43:28.601457   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:43:28.601465   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:43:28.619644   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:43:28.619660   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:43:28.635198   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:43:28.635207   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:43:28.650715   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:43:28.650723   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:43:28.661197   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:43:28.661208   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:43:31.185403   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:43:36.189268   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:43:36.276854   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:43:36.297167   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:43:36.297278   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:43:36.310317   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:43:36.310417   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:43:36.321641   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:43:36.321759   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:43:36.332822   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:43:36.332923   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:43:36.343857   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:43:36.343961   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:43:36.353779   77024 logs.go:274] 0 containers: []
W0111 14:43:36.353787   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:43:36.353874   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:43:36.363014   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:43:36.363108   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:43:36.372306   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:43:36.372318   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:43:36.372322   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:43:36.390802   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:43:36.390811   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:43:36.417682   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:43:36.417694   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:43:36.428197   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:43:36.428206   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:43:36.449373   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:43:36.449387   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:43:36.463534   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:43:36.463542   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:43:36.479201   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:43:36.479213   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:43:36.496487   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:43:36.496495   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:43:36.512046   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:43:36.512054   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:43:36.516852   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:43:36.516857   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:43:36.529126   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:43:36.529135   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:43:36.549108   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:43:36.549116   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:43:36.559281   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:43:36.559290   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:43:36.573499   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:43:36.573507   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:43:36.584352   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:43:36.584359   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:43:36.633639   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:43:36.633647   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:43:36.650357   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:43:36.650365   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:43:36.660767   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:43:36.660774   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:43:36.680428   77024 logs.go:123] Gathering logs for container status ...
I0111 14:43:36.680435   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:43:39.205320   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:43:44.207511   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:43:44.276515   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:43:44.289533   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:43:44.289660   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:43:44.312445   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:43:44.312564   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:43:44.329722   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:43:44.329868   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:43:44.342106   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:43:44.342215   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:43:44.353766   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:43:44.353873   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:43:44.363439   77024 logs.go:274] 0 containers: []
W0111 14:43:44.363447   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:43:44.363532   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:43:44.373575   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:43:44.373675   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:43:44.383022   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:43:44.383033   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:43:44.383037   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:43:44.394386   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:43:44.394395   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:43:44.411038   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:43:44.411046   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:43:44.431061   77024 logs.go:123] Gathering logs for container status ...
I0111 14:43:44.431071   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:43:44.446799   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:43:44.446807   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:43:44.464573   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:43:44.464582   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:43:44.515425   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:43:44.515438   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:43:44.529388   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:43:44.529395   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:43:44.540545   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:43:44.540552   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:43:44.550704   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:43:44.550711   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:43:44.555475   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:43:44.555482   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:43:44.568142   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:43:44.568146   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:43:44.579184   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:43:44.579192   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:43:44.590472   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:43:44.590482   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:43:44.608310   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:43:44.608314   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:43:44.626103   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:43:44.626110   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:43:44.642220   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:43:44.642224   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:43:44.653403   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:43:44.653410   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:43:44.666466   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:43:44.666468   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:43:47.178073   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:43:52.183015   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:43:52.276751   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:43:52.310324   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:43:52.310501   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:43:52.325094   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:43:52.325204   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:43:52.336739   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:43:52.336846   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:43:52.348341   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:43:52.348458   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:43:52.358283   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:43:52.358371   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:43:52.367180   77024 logs.go:274] 0 containers: []
W0111 14:43:52.367189   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:43:52.367280   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:43:52.376657   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:43:52.376756   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:43:52.385679   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:43:52.385697   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:43:52.385703   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:43:52.434412   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:43:52.434416   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:43:52.448582   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:43:52.448595   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:43:52.462394   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:43:52.462401   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:43:52.472658   77024 logs.go:123] Gathering logs for container status ...
I0111 14:43:52.472666   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:43:52.488613   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:43:52.488622   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:43:52.506943   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:43:52.506956   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:43:52.525184   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:43:52.525194   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:43:52.535030   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:43:52.535036   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:43:52.543729   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:43:52.543737   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:43:52.554124   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:43:52.554133   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:43:52.569384   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:43:52.569388   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:43:52.574324   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:43:52.574331   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:43:52.585548   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:43:52.585556   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:43:52.594883   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:43:52.594889   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:43:52.603013   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:43:52.603020   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:43:52.614033   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:43:52.614040   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:43:52.628047   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:43:52.628054   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:43:52.646979   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:43:52.646987   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:43:55.168183   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:44:00.173397   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:44:00.276725   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:44:00.303993   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:44:00.304178   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:44:00.318264   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:44:00.318394   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:44:00.332766   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:44:00.332884   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:44:00.343213   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:44:00.343312   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:44:00.353666   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:44:00.353774   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:44:00.366629   77024 logs.go:274] 0 containers: []
W0111 14:44:00.366636   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:44:00.366764   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:44:00.375276   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:44:00.375366   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:44:00.383551   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:44:00.383560   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:44:00.383564   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:44:00.394902   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:44:00.394909   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:44:00.412632   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:44:00.412640   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:44:00.433239   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:44:00.433246   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:44:00.438628   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:44:00.438634   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:44:00.455349   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:44:00.455355   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:44:00.463995   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:44:00.464002   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:44:00.473164   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:44:00.473170   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:44:00.482172   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:44:00.482177   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:44:00.496415   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:44:00.496422   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:44:00.542189   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:44:00.542196   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:44:00.553822   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:44:00.553828   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:44:00.565259   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:44:00.565266   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:44:00.574336   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:44:00.574344   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:44:00.592179   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:44:00.592189   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:44:00.606559   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:44:00.606566   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:44:00.616657   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:44:00.616663   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:44:00.627956   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:44:00.627977   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:44:00.652122   77024 logs.go:123] Gathering logs for container status ...
I0111 14:44:00.652130   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:44:03.173897   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:44:08.175610   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:44:08.276756   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:44:08.300194   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:44:08.300326   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:44:08.310469   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:44:08.310598   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:44:08.321306   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:44:08.321414   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:44:08.334614   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:44:08.334719   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:44:08.345225   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:44:08.345322   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:44:08.356347   77024 logs.go:274] 0 containers: []
W0111 14:44:08.356354   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:44:08.356442   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:44:08.364613   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:44:08.364697   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:44:08.373147   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:44:08.373161   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:44:08.373165   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:44:08.378745   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:44:08.378749   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:44:08.390697   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:44:08.390704   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:44:08.405604   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:44:08.405613   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:44:08.425293   77024 logs.go:123] Gathering logs for container status ...
I0111 14:44:08.425302   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:44:08.443704   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:44:08.443712   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:44:08.491105   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:44:08.491114   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:44:08.503630   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:44:08.503633   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:44:08.521082   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:44:08.521087   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:44:08.533648   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:44:08.533655   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:44:08.546866   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:44:08.546874   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:44:08.558257   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:44:08.558265   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:44:08.571385   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:44:08.571392   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:44:08.582107   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:44:08.582116   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:44:08.591943   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:44:08.591952   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:44:08.608326   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:44:08.608335   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:44:08.624363   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:44:08.624371   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:44:08.635497   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:44:08.635504   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:44:08.645860   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:44:08.645881   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:44:11.163040   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:44:16.169828   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": dial tcp 10.0.2.15:8443: i/o timeout (Client.Timeout exceeded while awaiting headers)
I0111 14:44:16.277389   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:44:16.308593   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:44:16.308726   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:44:16.321119   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:44:16.321223   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:44:16.331383   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:44:16.331466   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:44:16.340524   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:44:16.340613   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:44:16.349175   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:44:16.349241   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:44:16.358584   77024 logs.go:274] 0 containers: []
W0111 14:44:16.358592   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:44:16.358712   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:44:16.366394   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:44:16.366484   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:44:16.376489   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:44:16.376498   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:44:16.376502   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:44:16.385261   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:44:16.385268   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:44:16.401410   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:44:16.401419   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:44:16.417948   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:44:16.417954   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:44:16.437630   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:44:16.437636   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:44:16.452166   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:44:16.452176   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:44:16.461125   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:44:16.461132   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:44:16.470544   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:44:16.470549   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:44:16.479631   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:44:16.479658   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:44:16.487747   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:44:16.487754   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:44:16.514504   77024 logs.go:123] Gathering logs for container status ...
I0111 14:44:16.514519   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:44:16.529711   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:44:16.529719   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:44:16.547008   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:44:16.547017   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:44:16.552127   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:44:16.552134   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:44:16.561038   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:44:16.561046   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:44:16.574333   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:44:16.574342   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:44:16.588332   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:44:16.588340   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:44:16.644816   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:44:16.644824   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:44:16.659256   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:44:16.659264   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:44:19.172207   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:44:24.173690   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:44:24.276615   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:44:24.295332   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:44:24.295444   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:44:24.307545   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:44:24.307643   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:44:24.318330   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:44:24.318451   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:44:24.329641   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:44:24.329754   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:44:24.339809   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:44:24.339924   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:44:24.350459   77024 logs.go:274] 0 containers: []
W0111 14:44:24.350468   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:44:24.350554   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:44:24.364622   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:44:24.364753   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:44:24.375177   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:44:24.375189   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:44:24.375194   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:44:24.387052   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:44:24.387063   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:44:24.396896   77024 logs.go:123] Gathering logs for container status ...
I0111 14:44:24.396919   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:44:24.421982   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:44:24.421990   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:44:24.427590   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:44:24.427597   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:44:24.440779   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:44:24.440787   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:44:24.451432   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:44:24.451440   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:44:24.466531   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:44:24.466538   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:44:24.478367   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:44:24.478376   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:44:24.497875   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:44:24.497888   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:44:24.516279   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:44:24.516286   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:44:24.526868   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:44:24.526876   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:44:24.546888   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:44:24.546898   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:44:24.560303   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:44:24.560313   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:44:24.570263   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:44:24.570272   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:44:24.580782   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:44:24.580790   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:44:24.598953   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:44:24.598962   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:44:24.619604   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:44:24.619615   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:44:24.671530   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:44:24.671541   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:44:27.187482   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:44:32.202368   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:44:32.278358   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:44:32.308774   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:44:32.308881   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:44:32.322621   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:44:32.322738   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:44:32.334534   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:44:32.334853   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:44:32.350539   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:44:32.350665   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:44:32.359606   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:44:32.359724   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:44:32.369061   77024 logs.go:274] 0 containers: []
W0111 14:44:32.369066   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:44:32.369156   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:44:32.382032   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:44:32.382168   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:44:32.391866   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:44:32.391882   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:44:32.391893   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:44:32.404017   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:44:32.404025   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:44:32.419371   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:44:32.419379   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:44:32.438439   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:44:32.438448   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:44:32.508872   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:44:32.508881   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:44:32.526214   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:44:32.526226   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:44:32.539928   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:44:32.539932   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:44:32.557383   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:44:32.557392   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:44:32.569888   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:44:32.569897   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:44:32.584611   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:44:32.584620   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:44:32.594759   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:44:32.594783   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:44:32.614932   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:44:32.614949   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:44:32.621485   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:44:32.621494   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:44:32.643728   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:44:32.643737   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:44:32.655144   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:44:32.655153   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:44:32.666469   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:44:32.666478   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:44:32.683913   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:44:32.683922   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:44:32.709203   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:44:32.709214   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:44:32.722170   77024 logs.go:123] Gathering logs for container status ...
I0111 14:44:32.722179   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:44:35.243907   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:44:40.250384   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:44:40.276741   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:44:40.310054   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:44:40.310189   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:44:40.319908   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:44:40.320024   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:44:40.329014   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:44:40.329148   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:44:40.338915   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:44:40.339035   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:44:40.347543   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:44:40.347662   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:44:40.358055   77024 logs.go:274] 0 containers: []
W0111 14:44:40.358062   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:44:40.358152   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:44:40.367481   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:44:40.367655   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:44:40.378383   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:44:40.378396   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:44:40.378415   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:44:40.399181   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:44:40.399190   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:44:40.408724   77024 logs.go:123] Gathering logs for container status ...
I0111 14:44:40.408732   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:44:40.438419   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:44:40.438426   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:44:40.450407   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:44:40.450413   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:44:40.467157   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:44:40.467161   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:44:40.479410   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:44:40.479412   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:44:40.488662   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:44:40.488674   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:44:40.505065   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:44:40.505074   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:44:40.514045   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:44:40.514052   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:44:40.529324   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:44:40.529337   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:44:40.549431   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:44:40.549438   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:44:40.619418   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:44:40.619428   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:44:40.635341   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:44:40.635350   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:44:40.645543   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:44:40.645560   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:44:40.656365   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:44:40.656371   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:44:40.664816   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:44:40.664821   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:44:40.669910   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:44:40.669915   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:44:40.678652   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:44:40.678659   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:44:43.191714   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:44:48.193364   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:44:48.276699   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:44:48.290851   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:44:48.290967   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:44:48.302110   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:44:48.302214   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:44:48.311381   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:44:48.311468   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:44:48.319497   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:44:48.319580   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:44:48.327469   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:44:48.327547   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:44:48.335167   77024 logs.go:274] 0 containers: []
W0111 14:44:48.335174   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:44:48.335256   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:44:48.342874   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:44:48.342964   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:44:48.351306   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:44:48.351317   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:44:48.351321   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:44:48.362853   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:44:48.362862   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:44:48.375807   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:44:48.375815   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:44:48.394227   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:44:48.394236   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:44:48.412883   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:44:48.412890   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:44:48.427176   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:44:48.427183   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:44:48.440323   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:44:48.440331   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:44:48.450496   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:44:48.450504   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:44:48.459620   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:44:48.459628   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:44:48.469055   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:44:48.469064   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:44:48.487692   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:44:48.487700   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:44:48.504663   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:44:48.504671   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:44:48.522583   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:44:48.522597   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:44:48.534679   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:44:48.534684   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:44:48.547357   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:44:48.547366   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:44:48.557237   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:44:48.557245   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:44:48.562393   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:44:48.562399   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:44:48.609204   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:44:48.609212   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:44:48.619842   77024 logs.go:123] Gathering logs for container status ...
I0111 14:44:48.619851   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:44:51.136884   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:44:56.138448   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:44:56.276705   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:44:56.294650   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:44:56.294777   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:44:56.304812   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:44:56.304904   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:44:56.314704   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:44:56.314794   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:44:56.323787   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:44:56.323871   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:44:56.332224   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:44:56.332300   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:44:56.339849   77024 logs.go:274] 0 containers: []
W0111 14:44:56.339856   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:44:56.339949   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:44:56.348064   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:44:56.348148   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:44:56.357661   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:44:56.357671   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:44:56.357675   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:44:56.401471   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:44:56.401479   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:44:56.413139   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:44:56.413145   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:44:56.425195   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:44:56.425203   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:44:56.434385   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:44:56.434392   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:44:56.443152   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:44:56.443158   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:44:56.462091   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:44:56.462100   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:44:56.471653   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:44:56.471659   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:44:56.480198   77024 logs.go:123] Gathering logs for container status ...
I0111 14:44:56.480203   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:44:56.496707   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:44:56.496714   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:44:56.514513   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:44:56.514519   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:44:56.530711   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:44:56.530718   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:44:56.540112   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:44:56.540133   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:44:56.557350   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:44:56.557363   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:44:56.584023   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:44:56.584033   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:44:56.589380   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:44:56.589387   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:44:56.603883   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:44:56.603886   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:44:56.616852   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:44:56.616857   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:44:56.626731   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:44:56.626739   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:44:59.136444   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:45:04.142973   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:45:04.276753   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:45:04.298874   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:45:04.298998   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:45:04.310231   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:45:04.310357   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:45:04.320103   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:45:04.320204   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:45:04.328946   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:45:04.329038   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:45:04.337577   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:45:04.337664   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:45:04.345084   77024 logs.go:274] 0 containers: []
W0111 14:45:04.345089   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:45:04.345163   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:45:04.353044   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:45:04.353134   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:45:04.360563   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:45:04.360581   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:45:04.360599   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:45:04.375414   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:45:04.375421   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:45:04.385041   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:45:04.385046   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:45:04.393780   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:45:04.393786   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:45:04.403463   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:45:04.403469   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:45:04.451114   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:45:04.451122   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:45:04.465561   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:45:04.465575   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:45:04.475674   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:45:04.475682   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:45:04.489785   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:45:04.489791   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:45:04.503726   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:45:04.503734   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:45:04.519391   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:45:04.519399   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:45:04.538678   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:45:04.538693   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:45:04.543825   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:45:04.543830   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:45:04.559083   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:45:04.559090   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:45:04.570549   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:45:04.570556   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:45:04.579499   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:45:04.579506   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:45:04.591624   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:45:04.591630   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:45:04.599916   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:45:04.599923   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:45:04.617598   77024 logs.go:123] Gathering logs for container status ...
I0111 14:45:04.617606   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:45:07.136466   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:45:12.139612   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:45:12.276685   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:45:12.290548   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:45:12.290656   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:45:12.300106   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:45:12.300200   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:45:12.308909   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:45:12.308995   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:45:12.317322   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:45:12.317409   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:45:12.325502   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:45:12.325595   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:45:12.332985   77024 logs.go:274] 0 containers: []
W0111 14:45:12.332992   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:45:12.333071   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:45:12.340825   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:45:12.340917   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:45:12.350774   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:45:12.350788   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:45:12.350793   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:45:12.365581   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:45:12.365587   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:45:12.382896   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:45:12.382906   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:45:12.394411   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:45:12.394419   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:45:12.405674   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:45:12.405681   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:45:12.422806   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:45:12.422816   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:45:12.433834   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:45:12.433842   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:45:12.445593   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:45:12.445600   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:45:12.456269   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:45:12.456277   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:45:12.465179   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:45:12.465184   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:45:12.474366   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:45:12.474374   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:45:12.491147   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:45:12.491153   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:45:12.495881   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:45:12.495886   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:45:12.507225   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:45:12.507233   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:45:12.523178   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:45:12.523186   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:45:12.536990   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:45:12.536998   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:45:12.548785   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:45:12.548792   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:45:12.566600   77024 logs.go:123] Gathering logs for container status ...
I0111 14:45:12.566604   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:45:12.580516   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:45:12.580523   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:45:15.123529   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:45:20.128820   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:45:20.276698   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:45:20.293020   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:45:20.293120   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:45:20.303112   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:45:20.303349   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:45:20.316131   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:45:20.316240   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:45:20.328094   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:45:20.328196   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:45:20.336803   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:45:20.336890   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:45:20.345503   77024 logs.go:274] 0 containers: []
W0111 14:45:20.345510   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:45:20.345588   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:45:20.355150   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:45:20.355236   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:45:20.363965   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:45:20.363977   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:45:20.363981   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:45:20.376518   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:45:20.376524   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:45:20.391887   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:45:20.391895   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:45:20.403560   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:45:20.403569   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:45:20.413752   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:45:20.413755   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:45:20.421550   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:45:20.421557   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:45:20.445691   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:45:20.445698   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:45:20.459366   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:45:20.459374   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:45:20.479044   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:45:20.479061   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:45:20.489532   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:45:20.489536   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:45:20.498429   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:45:20.498436   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:45:20.512223   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:45:20.512232   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:45:20.524085   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:45:20.524093   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:45:20.539000   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:45:20.539007   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:45:20.564526   77024 logs.go:123] Gathering logs for container status ...
I0111 14:45:20.564535   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:45:20.581263   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:45:20.581270   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:45:20.599633   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:45:20.599642   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:45:20.646769   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:45:20.646777   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:45:20.660352   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:45:20.660360   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:45:23.171917   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:45:28.174530   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:45:28.276768   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:45:28.295755   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:45:28.295875   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:45:28.306762   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:45:28.306879   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:45:28.315783   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:45:28.315908   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:45:28.325146   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:45:28.325246   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:45:28.334336   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:45:28.334433   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:45:28.343682   77024 logs.go:274] 0 containers: []
W0111 14:45:28.343690   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:45:28.343766   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:45:28.352604   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:45:28.352706   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:45:28.361900   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:45:28.361913   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:45:28.361918   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:45:28.381505   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:45:28.381512   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:45:28.399330   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:45:28.399340   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:45:28.411249   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:45:28.411256   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:45:28.428052   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:45:28.428059   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:45:28.438581   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:45:28.438591   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:45:28.457334   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:45:28.457344   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:45:28.467066   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:45:28.467073   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:45:28.481576   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:45:28.481583   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:45:28.494258   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:45:28.494268   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:45:28.509320   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:45:28.509330   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:45:28.522289   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:45:28.522297   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:45:28.532613   77024 logs.go:123] Gathering logs for container status ...
I0111 14:45:28.532621   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:45:28.556805   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:45:28.556813   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:45:28.567233   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:45:28.567240   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:45:28.571704   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:45:28.571709   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:45:28.618625   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:45:28.618633   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:45:28.627912   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:45:28.627919   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:45:28.637054   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:45:28.637062   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:45:31.149639   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:45:36.151173   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:45:36.276800   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:45:36.299512   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:45:36.299621   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:45:36.309961   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:45:36.310055   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:45:36.317904   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:45:36.317985   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:45:36.325878   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:45:36.325970   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:45:36.333940   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:45:36.334031   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:45:36.342113   77024 logs.go:274] 0 containers: []
W0111 14:45:36.342119   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:45:36.342198   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:45:36.351067   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:45:36.351152   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:45:36.359641   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:45:36.359652   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:45:36.359656   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:45:36.364169   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:45:36.364172   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:45:36.372853   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:45:36.372860   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:45:36.381697   77024 logs.go:123] Gathering logs for container status ...
I0111 14:45:36.381704   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:45:36.399247   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:45:36.399254   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:45:36.411081   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:45:36.411088   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:45:36.422404   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:45:36.422413   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:45:36.435310   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:45:36.435317   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:45:36.447624   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:45:36.447629   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:45:36.464689   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:45:36.464695   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:45:36.506413   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:45:36.506419   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:45:36.524075   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:45:36.524083   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:45:36.538272   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:45:36.538278   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:45:36.547664   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:45:36.547670   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:45:36.556238   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:45:36.556248   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:45:36.574076   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:45:36.574082   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:45:36.591088   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:45:36.591093   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:45:36.601815   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:45:36.601821   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:45:36.612113   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:45:36.612119   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:45:39.136711   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:45:44.142224   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:45:44.276702   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:45:44.294508   77024 logs.go:274] 2 containers: [901357d3234c 61e2086ff549]
I0111 14:45:44.294652   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:45:44.304877   77024 logs.go:274] 2 containers: [02225bf315c9 3bce5f4dbff8]
I0111 14:45:44.304973   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:45:44.314584   77024 logs.go:274] 2 containers: [b31b954c61ea 6782b13ceb31]
I0111 14:45:44.314672   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:45:44.323634   77024 logs.go:274] 2 containers: [30d602f62259 3c6a8e6f9155]
I0111 14:45:44.323730   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:45:44.331481   77024 logs.go:274] 2 containers: [5f9fddc81cda 2aeeb88e9374]
I0111 14:45:44.331569   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:45:44.339776   77024 logs.go:274] 0 containers: []
W0111 14:45:44.339781   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:45:44.339853   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:45:44.347753   77024 logs.go:274] 2 containers: [9582d948dc48 86286f434fd9]
I0111 14:45:44.347827   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:45:44.357186   77024 logs.go:274] 2 containers: [772c4de6753a 8e3f6473f3b1]
I0111 14:45:44.357197   77024 logs.go:123] Gathering logs for container status ...
I0111 14:45:44.357201   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:45:44.371479   77024 logs.go:123] Gathering logs for kube-apiserver [901357d3234c] ...
I0111 14:45:44.371491   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 901357d3234c"
I0111 14:45:44.383278   77024 logs.go:123] Gathering logs for kube-apiserver [61e2086ff549] ...
I0111 14:45:44.383284   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 61e2086ff549"
I0111 14:45:44.399269   77024 logs.go:123] Gathering logs for etcd [02225bf315c9] ...
I0111 14:45:44.399277   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 02225bf315c9"
I0111 14:45:44.412433   77024 logs.go:123] Gathering logs for kube-scheduler [30d602f62259] ...
I0111 14:45:44.412442   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 30d602f62259"
I0111 14:45:44.423686   77024 logs.go:123] Gathering logs for kube-proxy [2aeeb88e9374] ...
I0111 14:45:44.423695   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2aeeb88e9374"
I0111 14:45:44.434280   77024 logs.go:123] Gathering logs for kube-controller-manager [8e3f6473f3b1] ...
I0111 14:45:44.434286   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8e3f6473f3b1"
I0111 14:45:44.451080   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:45:44.451088   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:45:44.469003   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:45:44.469010   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:45:44.486165   77024 logs.go:123] Gathering logs for storage-provisioner [86286f434fd9] ...
I0111 14:45:44.486174   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 86286f434fd9"
I0111 14:45:44.495518   77024 logs.go:123] Gathering logs for kube-controller-manager [772c4de6753a] ...
I0111 14:45:44.495525   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 772c4de6753a"
I0111 14:45:44.510443   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:45:44.510451   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:45:44.515337   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:45:44.515342   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:45:44.558727   77024 logs.go:123] Gathering logs for coredns [b31b954c61ea] ...
I0111 14:45:44.558734   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 b31b954c61ea"
I0111 14:45:44.567913   77024 logs.go:123] Gathering logs for kube-scheduler [3c6a8e6f9155] ...
I0111 14:45:44.567918   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3c6a8e6f9155"
I0111 14:45:44.581604   77024 logs.go:123] Gathering logs for storage-provisioner [9582d948dc48] ...
I0111 14:45:44.581611   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 9582d948dc48"
I0111 14:45:44.592515   77024 logs.go:123] Gathering logs for etcd [3bce5f4dbff8] ...
I0111 14:45:44.592525   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 3bce5f4dbff8"
I0111 14:45:44.606489   77024 logs.go:123] Gathering logs for coredns [6782b13ceb31] ...
I0111 14:45:44.606497   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 6782b13ceb31"
I0111 14:45:44.615763   77024 logs.go:123] Gathering logs for kube-proxy [5f9fddc81cda] ...
I0111 14:45:44.615769   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 5f9fddc81cda"
I0111 14:45:47.126791   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:45:52.131002   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:45:52.276668   77024 kubeadm.go:631] restartCluster took 4m9.932333375s
W0111 14:45:52.277944   77024 out.go:239] ü§¶  Unable to restart cluster, will reset it: apiserver health: apiserver healthz never reported healthy: cluster wait timed out during healthz check
I0111 14:45:52.277977   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force"
I0111 14:45:54.682602   77024 ssh_runner.go:235] Completed: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm reset --cri-socket /var/run/cri-dockerd.sock --force": (2.404606958s)
I0111 14:45:54.682903   77024 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0111 14:45:54.688698   77024 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0111 14:45:54.691744   77024 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0111 14:45:54.695366   77024 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0111 14:45:54.695382   77024 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.25.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem"
I0111 14:45:54.712109   77024 kubeadm.go:317] [init] Using Kubernetes version: v1.25.3
I0111 14:45:54.712201   77024 kubeadm.go:317] [preflight] Running pre-flight checks
I0111 14:45:54.773868   77024 kubeadm.go:317] [preflight] Pulling images required for setting up a Kubernetes cluster
I0111 14:45:54.773918   77024 kubeadm.go:317] [preflight] This might take a minute or two, depending on the speed of your internet connection
I0111 14:45:54.773961   77024 kubeadm.go:317] [preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
I0111 14:45:54.824702   77024 kubeadm.go:317] [certs] Using certificateDir folder "/var/lib/minikube/certs"
I0111 14:45:54.833228   77024 out.go:204]     ‚ñ™ Generating certificates and keys ...
I0111 14:45:54.833291   77024 kubeadm.go:317] [certs] Using existing ca certificate authority
I0111 14:45:54.833323   77024 kubeadm.go:317] [certs] Using existing apiserver certificate and key on disk
I0111 14:45:54.833359   77024 kubeadm.go:317] [certs] Using existing apiserver-kubelet-client certificate and key on disk
I0111 14:45:54.833386   77024 kubeadm.go:317] [certs] Using existing front-proxy-ca certificate authority
I0111 14:45:54.833421   77024 kubeadm.go:317] [certs] Using existing front-proxy-client certificate and key on disk
I0111 14:45:54.833449   77024 kubeadm.go:317] [certs] Using existing etcd/ca certificate authority
I0111 14:45:54.833488   77024 kubeadm.go:317] [certs] Using existing etcd/server certificate and key on disk
I0111 14:45:54.833530   77024 kubeadm.go:317] [certs] Using existing etcd/peer certificate and key on disk
I0111 14:45:54.833578   77024 kubeadm.go:317] [certs] Using existing etcd/healthcheck-client certificate and key on disk
I0111 14:45:54.833614   77024 kubeadm.go:317] [certs] Using existing apiserver-etcd-client certificate and key on disk
I0111 14:45:54.833633   77024 kubeadm.go:317] [certs] Using the existing "sa" key
I0111 14:45:54.833669   77024 kubeadm.go:317] [kubeconfig] Using kubeconfig folder "/etc/kubernetes"
I0111 14:45:54.999323   77024 kubeadm.go:317] [kubeconfig] Writing "admin.conf" kubeconfig file
I0111 14:45:55.039766   77024 kubeadm.go:317] [kubeconfig] Writing "kubelet.conf" kubeconfig file
I0111 14:45:55.235534   77024 kubeadm.go:317] [kubeconfig] Writing "controller-manager.conf" kubeconfig file
I0111 14:45:55.300663   77024 kubeadm.go:317] [kubeconfig] Writing "scheduler.conf" kubeconfig file
I0111 14:45:55.307844   77024 kubeadm.go:317] [kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
I0111 14:45:55.308229   77024 kubeadm.go:317] [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
I0111 14:45:55.308253   77024 kubeadm.go:317] [kubelet-start] Starting the kubelet
I0111 14:45:55.401978   77024 kubeadm.go:317] [control-plane] Using manifest folder "/etc/kubernetes/manifests"
I0111 14:45:55.406649   77024 out.go:204]     ‚ñ™ Booting up control plane ...
I0111 14:45:55.406736   77024 kubeadm.go:317] [control-plane] Creating static Pod manifest for "kube-apiserver"
I0111 14:45:55.406782   77024 kubeadm.go:317] [control-plane] Creating static Pod manifest for "kube-controller-manager"
I0111 14:45:55.406825   77024 kubeadm.go:317] [control-plane] Creating static Pod manifest for "kube-scheduler"
I0111 14:45:55.406902   77024 kubeadm.go:317] [etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
I0111 14:45:55.407037   77024 kubeadm.go:317] [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
I0111 14:46:00.412966   77024 kubeadm.go:317] [apiclient] All control plane components are healthy after 5.005101 seconds
I0111 14:46:00.413042   77024 kubeadm.go:317] [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
I0111 14:46:00.417885   77024 kubeadm.go:317] [kubelet] Creating a ConfigMap "kubelet-config" in namespace kube-system with the configuration for the kubelets in the cluster
I0111 14:46:00.931482   77024 kubeadm.go:317] [upload-certs] Skipping phase. Please see --upload-certs
I0111 14:46:00.931699   77024 kubeadm.go:317] [mark-control-plane] Marking the node minikube as control-plane by adding the labels: [node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers]
I0111 14:46:01.435778   77024 kubeadm.go:317] [bootstrap-token] Using token: z0ypem.wiw71ku84kpxia39
I0111 14:46:01.445657   77024 out.go:204]     ‚ñ™ Configuring RBAC rules ...
I0111 14:46:01.445789   77024 kubeadm.go:317] [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
I0111 14:46:01.445861   77024 kubeadm.go:317] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
I0111 14:46:01.447422   77024 kubeadm.go:317] [bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
I0111 14:46:01.448823   77024 kubeadm.go:317] [bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
I0111 14:46:01.449910   77024 kubeadm.go:317] [bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
I0111 14:46:01.450981   77024 kubeadm.go:317] [bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
I0111 14:46:01.457656   77024 kubeadm.go:317] [kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
I0111 14:46:01.617156   77024 kubeadm.go:317] [addons] Applied essential addon: CoreDNS
I0111 14:46:01.840392   77024 kubeadm.go:317] [addons] Applied essential addon: kube-proxy
I0111 14:46:01.841436   77024 kubeadm.go:317] 
I0111 14:46:01.841469   77024 kubeadm.go:317] Your Kubernetes control-plane has initialized successfully!
I0111 14:46:01.841472   77024 kubeadm.go:317] 
I0111 14:46:01.841513   77024 kubeadm.go:317] To start using your cluster, you need to run the following as a regular user:
I0111 14:46:01.841517   77024 kubeadm.go:317] 
I0111 14:46:01.841530   77024 kubeadm.go:317]   mkdir -p $HOME/.kube
I0111 14:46:01.841573   77024 kubeadm.go:317]   sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
I0111 14:46:01.841605   77024 kubeadm.go:317]   sudo chown $(id -u):$(id -g) $HOME/.kube/config
I0111 14:46:01.841606   77024 kubeadm.go:317] 
I0111 14:46:01.841633   77024 kubeadm.go:317] Alternatively, if you are the root user, you can run:
I0111 14:46:01.841634   77024 kubeadm.go:317] 
I0111 14:46:01.841682   77024 kubeadm.go:317]   export KUBECONFIG=/etc/kubernetes/admin.conf
I0111 14:46:01.841685   77024 kubeadm.go:317] 
I0111 14:46:01.841710   77024 kubeadm.go:317] You should now deploy a pod network to the cluster.
I0111 14:46:01.841757   77024 kubeadm.go:317] Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
I0111 14:46:01.841797   77024 kubeadm.go:317]   https://kubernetes.io/docs/concepts/cluster-administration/addons/
I0111 14:46:01.841799   77024 kubeadm.go:317] 
I0111 14:46:01.841842   77024 kubeadm.go:317] You can now join any number of control-plane nodes by copying certificate authorities
I0111 14:46:01.841879   77024 kubeadm.go:317] and service account keys on each node and then running the following as root:
I0111 14:46:01.841881   77024 kubeadm.go:317] 
I0111 14:46:01.841923   77024 kubeadm.go:317]   kubeadm join control-plane.minikube.internal:8443 --token z0ypem.wiw71ku84kpxia39 \
I0111 14:46:01.841982   77024 kubeadm.go:317] 	--discovery-token-ca-cert-hash sha256:d32e926aca87be297dc10c145531fe46b49ea668eb824524eb1380a9ef7bf08e \
I0111 14:46:01.841991   77024 kubeadm.go:317] 	--control-plane 
I0111 14:46:01.841992   77024 kubeadm.go:317] 
I0111 14:46:01.842036   77024 kubeadm.go:317] Then you can join any number of worker nodes by running the following on each as root:
I0111 14:46:01.842037   77024 kubeadm.go:317] 
I0111 14:46:01.842080   77024 kubeadm.go:317] kubeadm join control-plane.minikube.internal:8443 --token z0ypem.wiw71ku84kpxia39 \
I0111 14:46:01.842128   77024 kubeadm.go:317] 	--discovery-token-ca-cert-hash sha256:d32e926aca87be297dc10c145531fe46b49ea668eb824524eb1380a9ef7bf08e 
I0111 14:46:01.842287   77024 kubeadm.go:317] W0111 19:45:54.745040   10908 initconfiguration.go:119] Usage of CRI endpoints without URL scheme is deprecated and can cause kubelet errors in the future. Automatically prepending scheme "unix" to the "criSocket" with value "/var/run/cri-dockerd.sock". Please update your configuration!
I0111 14:46:01.842347   77024 kubeadm.go:317] 	[WARNING Service-Kubelet]: kubelet service is not enabled, please run 'systemctl enable kubelet.service'
I0111 14:46:01.842378   77024 cni.go:95] Creating CNI manager for ""
I0111 14:46:01.842382   77024 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0111 14:46:01.842396   77024 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0111 14:46:01.842781   77024 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.25.3/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I0111 14:46:01.842787   77024 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.25.3/kubectl label nodes minikube.k8s.io/version=v1.28.0 minikube.k8s.io/commit=986b1ebd987211ed16f8cc10aed7d2c42fc8392f minikube.k8s.io/name=minikube minikube.k8s.io/updated_at=2023_01_11T14_46_01_0700 minikube.k8s.io/primary=true --all --overwrite --kubeconfig=/var/lib/minikube/kubeconfig
I0111 14:46:01.846723   77024 ops.go:34] apiserver oom_adj: -16
I0111 14:46:01.909416   77024 kubeadm.go:1067] duration metric: took 66.759375ms to wait for elevateKubeSystemPrivileges.
I0111 14:46:01.909452   77024 host.go:66] Checking if "minikube" exists ...
I0111 14:46:01.914457   77024 main.go:134] libmachine: Using SSH client type: external
I0111 14:46:01.914482   77024 main.go:134] libmachine: Using SSH private key: /Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/id_rsa (-rw-------)
I0111 14:46:01.914496   77024 main.go:134] libmachine: &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/id_rsa -p 57661] /usr/bin/ssh <nil>}
I0111 14:46:01.914511   77024 main.go:134] libmachine: /usr/bin/ssh -F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@localhost -o IdentitiesOnly=yes -i /Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/id_rsa -p 57661 -f -NTL 57698:localhost:8443
I0111 14:46:02.029192   77024 kubeadm.go:398] StartCluster complete in 4m19.804192167s
I0111 14:46:02.029240   77024 settings.go:142] acquiring lock: {Name:mk938312746b5ba97d26bc5f780f62ff52befa87 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0111 14:46:02.032776   77024 settings.go:150] Updating kubeconfig:  /Users/Steve.X.Scammon.-ND/.kube/config
I0111 14:46:02.033794   77024 lock.go:35] WriteFile acquiring /Users/Steve.X.Scammon.-ND/.kube/config: {Name:mk12d40ff906dba732924b914132b1a882ee2bc5 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
W0111 14:46:32.042889   77024 kapi.go:226] failed getting deployment scale, will retry: Get "https://10.0.2.15:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 10.0.2.15:8443: i/o timeout
W0111 14:47:02.544742   77024 kapi.go:226] failed getting deployment scale, will retry: Get "https://10.0.2.15:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 10.0.2.15:8443: i/o timeout
W0111 14:47:33.044770   77024 kapi.go:226] failed getting deployment scale, will retry: Get "https://10.0.2.15:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 10.0.2.15:8443: i/o timeout
W0111 14:48:03.549088   77024 kapi.go:226] failed getting deployment scale, will retry: Get "https://10.0.2.15:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 10.0.2.15:8443: i/o timeout
W0111 14:48:34.045083   77024 kapi.go:226] failed getting deployment scale, will retry: Get "https://10.0.2.15:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 10.0.2.15:8443: i/o timeout
W0111 14:49:04.046900   77024 kapi.go:226] failed getting deployment scale, will retry: Get "https://10.0.2.15:8443/apis/apps/v1/namespaces/kube-system/deployments/coredns/scale": dial tcp 10.0.2.15:8443: i/o timeout
I0111 14:49:04.050253   77024 kapi.go:241] timed out trying to rescale deployment "coredns" in namespace "kube-system" and context "minikube" to 1: timed out waiting for the condition
E0111 14:49:04.050455   77024 start.go:268] Unable to scale down deployment "coredns" in namespace "kube-system" to 1 replica: timed out waiting for the condition
I0111 14:49:04.063953   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0111 14:49:04.065052   77024 start.go:212] Will wait 6m0s for node &{Name: IP:10.0.2.15 Port:8443 KubernetesVersion:v1.25.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0111 14:49:04.069850   77024 out.go:177] üîé  Verifying Kubernetes components...
I0111 14:49:04.065736   77024 addons.go:486] enableAddons start: toEnable=map[default-storageclass:true storage-provisioner:true], additional=[]
I0111 14:49:04.069937   77024 config.go:180] Loaded profile config "minikube": Driver=qemu2, ContainerRuntime=docker, KubernetesVersion=v1.25.3
I0111 14:49:04.077900   77024 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0111 14:49:04.078150   77024 addons.go:65] Setting storage-provisioner=true in profile "minikube"
I0111 14:49:04.078156   77024 addons.go:65] Setting default-storageclass=true in profile "minikube"
I0111 14:49:04.078210   77024 addons.go:227] Setting addon storage-provisioner=true in "minikube"
I0111 14:49:04.078227   77024 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
W0111 14:49:04.078216   77024 addons.go:236] addon storage-provisioner should already be in state true
I0111 14:49:04.079506   77024 host.go:66] Checking if "minikube" exists ...
I0111 14:49:04.091940   77024 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0111 14:49:04.097334   77024 addons.go:419] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0111 14:49:04.097345   77024 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0111 14:49:04.097377   77024 sshutil.go:53] new ssh client: &{IP:localhost Port:57661 SSHKeyPath:/Users/Steve.X.Scammon.-ND/.minikube/machines/minikube/id_rsa Username:docker}
I0111 14:49:04.145862   77024 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.25.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0111 14:49:04.151259   77024 api_server.go:51] waiting for apiserver process to appear ...
I0111 14:49:04.151329   77024 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0111 14:49:04.151907   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           10.0.2.2 host.minikube.internal\n           fallthrough\n        }' | sudo /var/lib/minikube/binaries/v1.25.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I0111 14:49:04.734138   77024 api_server.go:71] duration metric: took 669.033042ms to wait for apiserver process to appear ...
I0111 14:49:04.734155   77024 api_server.go:87] waiting for apiserver healthz status ...
I0111 14:49:04.734162   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:49:04.734394   77024 start.go:826] {"host.minikube.internal": 10.0.2.2} host record injected into CoreDNS
I0111 14:49:09.735802   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:49:10.244559   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:49:15.248175   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:49:15.737006   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:49:20.737881   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:49:21.237317   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:49:26.248157   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:49:26.736122   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:49:31.737011   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:49:31.737087   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
W0111 14:49:34.093830   77024 out.go:239] ‚ùó  Enabling 'default-storageclass' returned an error: running callbacks: [Error making standard the default storage class: Error listing StorageClasses: Get "https://10.0.2.15:8443/apis/storage.k8s.io/v1/storageclasses": dial tcp 10.0.2.15:8443: i/o timeout]
I0111 14:49:34.106641   77024 out.go:177] üåü  Enabled addons: storage-provisioner
I0111 14:49:34.110649   77024 addons.go:488] enableAddons completed in 30.045478875s
I0111 14:49:36.743149   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:49:36.745584   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:49:41.747349   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:49:42.237018   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:49:47.238350   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": dial tcp 10.0.2.15:8443: i/o timeout (Client.Timeout exceeded while awaiting headers)
I0111 14:49:47.737034   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:49:52.737921   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": dial tcp 10.0.2.15:8443: i/o timeout (Client.Timeout exceeded while awaiting headers)
I0111 14:49:53.237166   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:49:58.238537   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:49:58.737084   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:50:03.739380   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:50:04.237400   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:50:04.265393   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:50:04.265552   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:50:04.275801   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:50:04.275921   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:50:04.285807   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:50:04.285897   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:50:04.295713   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:50:04.295802   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:50:04.305550   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:50:04.305694   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:50:04.314454   77024 logs.go:274] 0 containers: []
W0111 14:50:04.314461   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:50:04.314536   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:50:04.322608   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:50:04.322701   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:50:04.331377   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:50:04.331394   77024 logs.go:123] Gathering logs for container status ...
I0111 14:50:04.331398   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:50:04.352639   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:50:04.352647   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:50:04.389293   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:50:04.389302   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:50:04.458462   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:50:04.458471   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:50:04.471333   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:50:04.471342   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:50:04.486664   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:50:04.486673   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:50:04.500176   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:50:04.500182   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:50:04.516304   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:50:04.516313   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:50:04.522601   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:50:04.522606   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:50:04.532832   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:50:04.532838   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:50:04.541338   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:50:04.541345   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:50:04.551366   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:50:04.551372   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:50:04.560946   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:50:04.560952   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:50:07.092699   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:50:12.094219   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:50:12.237236   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:50:12.252415   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:50:12.252524   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:50:12.264624   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:50:12.264749   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:50:12.276741   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:50:12.276860   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:50:12.287864   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:50:12.287975   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:50:12.298597   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:50:12.298750   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:50:12.308231   77024 logs.go:274] 0 containers: []
W0111 14:50:12.308238   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:50:12.308325   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:50:12.317236   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:50:12.317346   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:50:12.326953   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:50:12.326975   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:50:12.326980   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:50:12.343301   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:50:12.343313   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:50:12.368591   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:50:12.368618   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:50:12.384305   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:50:12.384315   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:50:12.394974   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:50:12.394987   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:50:12.435051   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:50:12.435073   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:50:12.442412   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:50:12.442420   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:50:12.500572   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:50:12.500585   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:50:12.513844   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:50:12.513852   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:50:12.529835   77024 logs.go:123] Gathering logs for container status ...
I0111 14:50:12.529849   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:50:12.547448   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:50:12.547456   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:50:12.559528   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:50:12.559535   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:50:12.571469   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:50:12.571481   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:50:15.099832   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:50:20.123838   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:50:20.237139   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:50:20.259833   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:50:20.259952   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:50:20.270037   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:50:20.270138   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:50:20.281161   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:50:20.281250   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:50:20.304237   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:50:20.304360   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:50:20.315624   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:50:20.315743   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:50:20.325328   77024 logs.go:274] 0 containers: []
W0111 14:50:20.325336   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:50:20.325419   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:50:20.335650   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:50:20.335760   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:50:20.345496   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:50:20.345509   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:50:20.345516   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:50:20.394886   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:50:20.394894   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:50:20.408355   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:50:20.408364   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:50:20.422109   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:50:20.422117   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:50:20.432451   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:50:20.432462   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:50:20.441705   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:50:20.441713   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:50:20.457478   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:50:20.457486   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:50:20.486601   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:50:20.486620   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:50:20.522944   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:50:20.522953   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:50:20.528947   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:50:20.528967   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:50:20.541451   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:50:20.541472   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:50:20.551297   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:50:20.551307   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:50:20.561554   77024 logs.go:123] Gathering logs for container status ...
I0111 14:50:20.561577   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:50:23.078165   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:50:28.080432   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:50:28.237266   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:50:28.253537   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:50:28.253647   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:50:28.262726   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:50:28.262814   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:50:28.271248   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:50:28.271339   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:50:28.284044   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:50:28.284128   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:50:28.292509   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:50:28.292601   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:50:28.300776   77024 logs.go:274] 0 containers: []
W0111 14:50:28.300782   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:50:28.300849   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:50:28.309259   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:50:28.309328   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:50:28.321621   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:50:28.321632   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:50:28.321636   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:50:28.328107   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:50:28.328112   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:50:28.380181   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:50:28.380189   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:50:28.393339   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:50:28.393347   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:50:28.402713   77024 logs.go:123] Gathering logs for container status ...
I0111 14:50:28.402723   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:50:28.418662   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:50:28.418670   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:50:28.428035   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:50:28.428041   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:50:28.443735   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:50:28.443745   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:50:28.469761   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:50:28.469770   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:50:28.505514   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:50:28.505533   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:50:28.517459   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:50:28.517468   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:50:28.528410   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:50:28.528417   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:50:28.537090   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:50:28.537096   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:50:31.051179   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:50:36.065255   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": dial tcp 10.0.2.15:8443: i/o timeout (Client.Timeout exceeded while awaiting headers)
I0111 14:50:36.237466   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:50:36.268700   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:50:36.268854   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:50:36.283547   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:50:36.283650   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:50:36.293798   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:50:36.293897   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:50:36.301895   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:50:36.301983   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:50:36.310850   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:50:36.311373   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:50:36.334048   77024 logs.go:274] 0 containers: []
W0111 14:50:36.334055   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:50:36.334137   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:50:36.343091   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:50:36.343198   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:50:36.353192   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:50:36.353205   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:50:36.353210   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:50:36.363311   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:50:36.363318   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:50:36.372917   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:50:36.372922   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:50:36.389680   77024 logs.go:123] Gathering logs for container status ...
I0111 14:50:36.389695   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:50:36.408845   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:50:36.408857   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:50:36.458550   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:50:36.458557   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:50:36.474808   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:50:36.474814   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:50:36.487955   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:50:36.487962   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:50:36.497557   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:50:36.497562   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:50:36.510191   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:50:36.510197   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:50:36.519430   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:50:36.519436   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:50:36.545144   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:50:36.545156   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:50:36.577528   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:50:36.577535   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:50:39.083398   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:50:44.085789   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:50:44.242182   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:50:44.270030   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:50:44.270272   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:50:44.285869   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:50:44.285975   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:50:44.296308   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:50:44.296402   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:50:44.305334   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:50:44.305418   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:50:44.313737   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:50:44.313841   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:50:44.321486   77024 logs.go:274] 0 containers: []
W0111 14:50:44.321491   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:50:44.321562   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:50:44.329126   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:50:44.329187   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:50:44.336527   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:50:44.336536   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:50:44.336540   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:50:44.361034   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:50:44.361039   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:50:44.372756   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:50:44.372761   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:50:44.381476   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:50:44.381482   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:50:44.394543   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:50:44.394550   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:50:44.403254   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:50:44.403261   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:50:44.417862   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:50:44.417869   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:50:44.426686   77024 logs.go:123] Gathering logs for container status ...
I0111 14:50:44.426693   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:50:44.439355   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:50:44.439362   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:50:44.471781   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:50:44.471797   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:50:44.476921   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:50:44.476928   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:50:44.520089   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:50:44.520094   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:50:44.535811   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:50:44.535817   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:50:47.044434   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:50:52.060632   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:50:52.238981   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:50:52.263221   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:50:52.263525   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:50:52.278740   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:50:52.278845   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:50:52.291845   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:50:52.291943   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:50:52.300878   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:50:52.300969   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:50:52.310957   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:50:52.311022   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:50:52.318319   77024 logs.go:274] 0 containers: []
W0111 14:50:52.318335   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:50:52.318415   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:50:52.331676   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:50:52.331789   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:50:52.339459   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:50:52.339467   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:50:52.339470   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:50:52.356023   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:50:52.356033   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:50:52.382514   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:50:52.382531   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:50:52.399913   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:50:52.399921   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:50:52.411235   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:50:52.411241   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:50:52.419786   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:50:52.419797   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:50:52.433890   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:50:52.433899   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:50:52.443133   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:50:52.443138   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:50:52.451727   77024 logs.go:123] Gathering logs for container status ...
I0111 14:50:52.451732   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:50:52.465377   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:50:52.465386   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:50:52.503557   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:50:52.503570   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:50:52.509270   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:50:52.509276   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:50:52.552306   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:50:52.552314   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:50:55.062202   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:51:00.064870   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:51:00.237459   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:51:00.270097   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:51:00.270352   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:51:00.290098   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:51:00.290269   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:51:00.306351   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:51:00.306453   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:51:00.317362   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:51:00.317463   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:51:00.326282   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:51:00.326368   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:51:00.335505   77024 logs.go:274] 0 containers: []
W0111 14:51:00.335511   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:51:00.335613   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:51:00.344818   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:51:00.344926   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:51:00.352783   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:51:00.352795   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:51:00.352800   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:51:00.368882   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:51:00.368889   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:51:00.378730   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:51:00.378738   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:51:00.403272   77024 logs.go:123] Gathering logs for container status ...
I0111 14:51:00.403282   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:51:00.416441   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:51:00.416449   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:51:00.421845   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:51:00.421850   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:51:00.433814   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:51:00.433822   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:51:00.446775   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:51:00.446782   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:51:00.457063   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:51:00.457070   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:51:00.465555   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:51:00.465561   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:51:00.480464   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:51:00.480469   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:51:00.513114   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:51:00.513121   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:51:00.553266   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:51:00.553276   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:51:03.066020   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:51:08.068155   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:51:08.237592   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:51:08.260865   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:51:08.261106   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:51:08.280137   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:51:08.280239   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:51:08.290646   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:51:08.290746   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:51:08.299819   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:51:08.299902   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:51:08.307257   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:51:08.307338   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:51:08.314491   77024 logs.go:274] 0 containers: []
W0111 14:51:08.314495   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:51:08.314557   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:51:08.322325   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:51:08.322397   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:51:08.329939   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:51:08.329946   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:51:08.329950   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:51:08.344433   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:51:08.344438   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:51:08.370963   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:51:08.370967   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:51:08.411474   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:51:08.411481   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:51:08.423387   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:51:08.423396   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:51:08.432010   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:51:08.432015   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:51:08.440441   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:51:08.440448   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:51:08.453100   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:51:08.453106   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:51:08.462608   77024 logs.go:123] Gathering logs for container status ...
I0111 14:51:08.462616   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:51:08.474388   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:51:08.474398   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:51:08.508559   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:51:08.508566   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:51:08.513560   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:51:08.513565   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:51:08.525024   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:51:08.525030   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:51:11.035460   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:51:16.042248   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:51:16.237106   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:51:16.271275   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:51:16.271545   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:51:16.285510   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:51:16.285623   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:51:16.295600   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:51:16.295686   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:51:16.304339   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:51:16.304418   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:51:16.313221   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:51:16.313317   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:51:16.324590   77024 logs.go:274] 0 containers: []
W0111 14:51:16.324597   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:51:16.324682   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:51:16.335598   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:51:16.335672   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:51:16.343650   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:51:16.343661   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:51:16.343666   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:51:16.354072   77024 logs.go:123] Gathering logs for container status ...
I0111 14:51:16.354080   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:51:16.372593   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:51:16.372604   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:51:16.409315   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:51:16.409329   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:51:16.414564   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:51:16.414567   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:51:16.428706   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:51:16.428714   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:51:16.437092   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:51:16.437097   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:51:16.448274   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:51:16.448280   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:51:16.463877   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:51:16.463888   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:51:16.490773   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:51:16.490781   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:51:16.545013   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:51:16.545021   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:51:16.563484   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:51:16.563494   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:51:16.576605   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:51:16.576614   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:51:19.091816   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:51:24.097973   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:51:24.240781   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:51:24.276285   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:51:24.276528   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:51:24.292100   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:51:24.292216   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:51:24.303409   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:51:24.303495   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:51:24.312597   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:51:24.312681   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:51:24.321810   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:51:24.321890   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:51:24.329719   77024 logs.go:274] 0 containers: []
W0111 14:51:24.329725   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:51:24.329804   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:51:24.339530   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:51:24.339603   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:51:24.347558   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:51:24.347572   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:51:24.347575   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:51:24.359744   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:51:24.359750   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:51:24.374025   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:51:24.374033   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:51:24.382978   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:51:24.382984   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:51:24.394764   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:51:24.394772   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:51:24.403139   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:51:24.403144   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:51:24.437720   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:51:24.437727   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:51:24.442030   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:51:24.442034   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:51:24.482860   77024 logs.go:123] Gathering logs for container status ...
I0111 14:51:24.482866   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:51:24.496460   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:51:24.496470   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:51:24.523429   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:51:24.523436   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:51:24.533621   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:51:24.533628   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:51:24.543084   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:51:24.543090   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:51:27.060144   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:51:32.064251   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:51:32.246174   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:51:32.267851   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:51:32.267965   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:51:32.280527   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:51:32.280648   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:51:32.292759   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:51:32.292880   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:51:32.304525   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:51:32.304608   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:51:32.313491   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:51:32.313581   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:51:32.321655   77024 logs.go:274] 0 containers: []
W0111 14:51:32.321660   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:51:32.321737   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:51:32.330411   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:51:32.330489   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:51:32.338066   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:51:32.338076   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:51:32.338080   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:51:32.373277   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:51:32.373284   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:51:32.378050   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:51:32.378053   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:51:32.390748   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:51:32.390756   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:51:32.405767   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:51:32.405772   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:51:32.453266   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:51:32.453273   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:51:32.468906   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:51:32.468912   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:51:32.479755   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:51:32.479764   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:51:32.488118   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:51:32.488123   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:51:32.496850   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:51:32.496855   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:51:32.505323   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:51:32.505329   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:51:32.513724   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:51:32.513735   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:51:32.540769   77024 logs.go:123] Gathering logs for container status ...
I0111 14:51:32.540774   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:51:35.054672   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:51:40.057382   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:51:40.244417   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:51:40.295183   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:51:40.295466   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:51:40.318836   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:51:40.319029   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:51:40.329257   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:51:40.329352   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:51:40.338632   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:51:40.338721   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:51:40.346795   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:51:40.346872   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:51:40.354732   77024 logs.go:274] 0 containers: []
W0111 14:51:40.354737   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:51:40.354811   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:51:40.362058   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:51:40.362152   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:51:40.369640   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:51:40.369652   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:51:40.369657   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:51:40.381636   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:51:40.381645   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:51:40.395888   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:51:40.395893   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:51:40.420990   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:51:40.420998   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:51:40.453462   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:51:40.453470   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:51:40.458051   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:51:40.458055   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:51:40.501209   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:51:40.501219   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:51:40.511217   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:51:40.511226   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:51:40.520944   77024 logs.go:123] Gathering logs for container status ...
I0111 14:51:40.520957   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:51:40.536223   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:51:40.536230   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:51:40.548250   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:51:40.548256   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:51:40.559038   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:51:40.559044   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:51:40.567655   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:51:40.567660   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:51:43.081719   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:51:48.088705   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:51:48.247571   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:51:48.277543   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:51:48.277682   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:51:48.291508   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:51:48.291622   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:51:48.304352   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:51:48.304465   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:51:48.318214   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:51:48.318316   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:51:48.326840   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:51:48.326930   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:51:48.335978   77024 logs.go:274] 0 containers: []
W0111 14:51:48.335985   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:51:48.336067   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:51:48.343835   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:51:48.343915   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:51:48.351834   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:51:48.351844   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:51:48.351850   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:51:48.377597   77024 logs.go:123] Gathering logs for container status ...
I0111 14:51:48.377604   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:51:48.389787   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:51:48.389796   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:51:48.421548   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:51:48.421555   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:51:48.439804   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:51:48.439810   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:51:48.448896   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:51:48.448903   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:51:48.463745   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:51:48.463749   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:51:48.476278   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:51:48.476287   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:51:48.488068   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:51:48.488074   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:51:48.496729   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:51:48.496734   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:51:48.501479   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:51:48.501484   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:51:48.542530   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:51:48.542538   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:51:48.554382   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:51:48.554388   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:51:51.064221   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:51:56.067083   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:51:56.245468   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:51:56.265100   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:51:56.265287   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:51:56.278008   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:51:56.278104   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:51:56.288066   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:51:56.288153   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:51:56.298415   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:51:56.298506   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:51:56.306111   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:51:56.306202   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:51:56.313667   77024 logs.go:274] 0 containers: []
W0111 14:51:56.313673   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:51:56.313747   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:51:56.321693   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:51:56.321770   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:51:56.329935   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:51:56.329943   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:51:56.329947   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:51:56.339789   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:51:56.339794   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:51:56.351242   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:51:56.351248   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:51:56.362349   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:51:56.362357   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:51:56.378983   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:51:56.378989   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:51:56.402984   77024 logs.go:123] Gathering logs for container status ...
I0111 14:51:56.402991   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:51:56.418247   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:51:56.418252   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:51:56.450483   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:51:56.450489   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:51:56.455238   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:51:56.455242   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:51:56.473671   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:51:56.473678   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:51:56.482860   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:51:56.482865   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:51:56.495358   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:51:56.495363   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:51:56.535552   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:51:56.535559   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:51:59.049647   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:52:04.051938   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:52:04.248412   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:52:04.284126   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:52:04.284453   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:52:04.298715   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:52:04.298831   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:52:04.309597   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:52:04.309705   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:52:04.319416   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:52:04.319510   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:52:04.328027   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:52:04.328108   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:52:04.335624   77024 logs.go:274] 0 containers: []
W0111 14:52:04.335629   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:52:04.335708   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:52:04.344395   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:52:04.344467   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:52:04.352235   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:52:04.352247   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:52:04.352251   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:52:04.400493   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:52:04.400500   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:52:04.412700   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:52:04.412708   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:52:04.422175   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:52:04.422180   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:52:04.430590   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:52:04.430595   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:52:04.442535   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:52:04.442541   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:52:04.451772   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:52:04.451778   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:52:04.460446   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:52:04.460451   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:52:04.478974   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:52:04.478980   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:52:04.506375   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:52:04.506382   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:52:04.540721   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:52:04.540728   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:52:04.546146   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:52:04.546152   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:52:04.557702   77024 logs.go:123] Gathering logs for container status ...
I0111 14:52:04.557708   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:52:07.071489   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:52:12.074948   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:52:12.251939   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:52:12.286774   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:52:12.287045   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:52:12.301879   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:52:12.302031   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:52:12.313036   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:52:12.313142   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:52:12.322785   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:52:12.322874   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:52:12.332777   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:52:12.332855   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:52:12.342040   77024 logs.go:274] 0 containers: []
W0111 14:52:12.342046   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:52:12.342127   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:52:12.357730   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:52:12.357828   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:52:12.366430   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:52:12.366439   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:52:12.366444   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:52:12.406067   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:52:12.406074   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:52:12.418285   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:52:12.418291   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:52:12.430231   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:52:12.430237   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:52:12.440783   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:52:12.440791   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:52:12.466505   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:52:12.466513   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:52:12.478320   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:52:12.478327   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:52:12.493049   77024 logs.go:123] Gathering logs for container status ...
I0111 14:52:12.493062   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:52:12.507109   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:52:12.507115   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:52:12.541400   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:52:12.541407   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:52:12.546337   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:52:12.546340   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:52:12.558414   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:52:12.558420   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:52:12.567072   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:52:12.567078   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:52:15.076765   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:52:20.078944   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:52:20.250357   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:52:20.292007   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:52:20.292123   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:52:20.302561   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:52:20.302677   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:52:20.315787   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:52:20.315913   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:52:20.326163   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:52:20.326288   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:52:20.334287   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:52:20.334375   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:52:20.343430   77024 logs.go:274] 0 containers: []
W0111 14:52:20.343438   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:52:20.343536   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:52:20.351456   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:52:20.351532   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:52:20.359099   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:52:20.359109   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:52:20.359113   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:52:20.367872   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:52:20.367878   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:52:20.376215   77024 logs.go:123] Gathering logs for container status ...
I0111 14:52:20.376220   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:52:20.395012   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:52:20.395020   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:52:20.427939   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:52:20.427950   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:52:20.443128   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:52:20.443135   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:52:20.452569   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:52:20.452576   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:52:20.460902   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:52:20.460907   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:52:20.476742   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:52:20.476748   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:52:20.481286   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:52:20.481290   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:52:20.532456   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:52:20.532464   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:52:20.544935   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:52:20.544941   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:52:20.560797   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:52:20.560805   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:52:23.088993   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:52:28.093145   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:52:28.250875   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:52:28.269819   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:52:28.269934   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:52:28.283351   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:52:28.283452   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:52:28.297021   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:52:28.297131   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:52:28.307066   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:52:28.307154   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:52:28.316927   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:52:28.317053   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:52:28.326782   77024 logs.go:274] 0 containers: []
W0111 14:52:28.326786   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:52:28.326851   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:52:28.334989   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:52:28.335075   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:52:28.342512   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:52:28.342521   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:52:28.342524   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:52:28.353534   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:52:28.353539   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:52:28.361906   77024 logs.go:123] Gathering logs for container status ...
I0111 14:52:28.361912   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:52:28.376263   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:52:28.376269   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:52:28.385135   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:52:28.385141   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:52:28.396712   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:52:28.396719   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:52:28.405217   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:52:28.405221   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:52:28.413187   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:52:28.413211   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:52:28.448118   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:52:28.448133   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:52:28.452951   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:52:28.452957   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:52:28.495145   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:52:28.495155   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:52:28.508165   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:52:28.508173   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:52:28.522367   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:52:28.522374   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:52:31.051467   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:52:36.053572   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:52:36.249850   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:52:36.291362   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:52:36.291465   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:52:36.305749   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:52:36.305850   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:52:36.317427   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:52:36.317529   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:52:36.328042   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:52:36.328142   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:52:36.337592   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:52:36.337703   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:52:36.345479   77024 logs.go:274] 0 containers: []
W0111 14:52:36.345483   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:52:36.345548   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:52:36.353072   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:52:36.353167   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:52:36.362275   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:52:36.362288   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:52:36.362292   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:52:36.397277   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:52:36.397284   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:52:36.440856   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:52:36.440863   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:52:36.451251   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:52:36.451258   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:52:36.460536   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:52:36.460542   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:52:36.474487   77024 logs.go:123] Gathering logs for container status ...
I0111 14:52:36.474497   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:52:36.486887   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:52:36.486898   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:52:36.491700   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:52:36.491705   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:52:36.504612   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:52:36.504618   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:52:36.515930   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:52:36.515935   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:52:36.524420   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:52:36.524426   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:52:36.538178   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:52:36.538185   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:52:36.547036   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:52:36.547042   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:52:39.072471   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:52:44.074725   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:52:44.249633   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:52:44.272916   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:52:44.273028   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:52:44.285952   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:52:44.286073   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:52:44.298395   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:52:44.298498   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:52:44.309202   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:52:44.309287   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:52:44.319037   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:52:44.319142   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:52:44.327630   77024 logs.go:274] 0 containers: []
W0111 14:52:44.327634   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:52:44.327699   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:52:44.335722   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:52:44.335797   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:52:44.344153   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:52:44.344162   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:52:44.344165   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:52:44.378462   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:52:44.378469   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:52:44.391173   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:52:44.391178   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:52:44.399851   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:52:44.399857   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:52:44.409361   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:52:44.409366   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:52:44.423411   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:52:44.423416   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:52:44.450726   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:52:44.450735   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:52:44.455628   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:52:44.455632   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:52:44.496315   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:52:44.496326   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:52:44.508743   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:52:44.508748   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:52:44.519881   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:52:44.519886   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:52:44.530399   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:52:44.530406   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:52:44.539621   77024 logs.go:123] Gathering logs for container status ...
I0111 14:52:44.539627   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:52:47.053014   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:52:52.054843   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:52:52.247050   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:52:52.284672   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:52:52.284892   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:52:52.295659   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:52:52.295782   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:52:52.306254   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:52:52.306365   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:52:52.317455   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:52:52.317551   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:52:52.327138   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:52:52.327230   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:52:52.337426   77024 logs.go:274] 0 containers: []
W0111 14:52:52.337431   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:52:52.337508   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:52:52.345323   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:52:52.345407   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:52:52.353366   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:52:52.353374   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:52:52.353378   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:52:52.362252   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:52:52.362257   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:52:52.376158   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:52:52.376164   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:52:52.407812   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:52:52.407820   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:52:52.412093   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:52:52.412097   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:52:52.451025   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:52:52.451032   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:52:52.462707   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:52:52.462711   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:52:52.473642   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:52:52.473648   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:52:52.494053   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:52:52.494060   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:52:52.519474   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:52:52.519484   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:52:52.531416   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:52:52.531423   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:52:52.540506   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:52:52.540514   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:52:52.555484   77024 logs.go:123] Gathering logs for container status ...
I0111 14:52:52.555494   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:52:55.069986   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:53:00.071505   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:53:00.246676   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:53:00.270992   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:53:00.271094   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:53:00.281577   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:53:00.281670   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:53:00.292495   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:53:00.292596   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:53:00.303805   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:53:00.303923   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:53:00.314564   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:53:00.314683   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:53:00.327882   77024 logs.go:274] 0 containers: []
W0111 14:53:00.327889   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:53:00.327985   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:53:00.336837   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:53:00.336923   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:53:00.345748   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:53:00.345755   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:53:00.345759   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:53:00.381805   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:53:00.381822   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:53:00.425604   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:53:00.425610   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:53:00.437677   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:53:00.437689   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:53:00.449440   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:53:00.449448   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:53:00.460123   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:53:00.460131   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:53:00.469265   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:53:00.469271   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:53:00.497080   77024 logs.go:123] Gathering logs for container status ...
I0111 14:53:00.497089   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:53:00.511539   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:53:00.511546   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:53:00.516054   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:53:00.516063   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:53:00.524692   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:53:00.524698   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:53:00.537845   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:53:00.537852   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:53:00.547319   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:53:00.547324   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:53:03.064338   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:53:08.067074   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:53:08.246354   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:53:08.259133   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:53:08.259226   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:53:08.267354   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:53:08.267448   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:53:08.276581   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:53:08.276655   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:53:08.287064   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:53:08.287176   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:53:08.298455   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:53:08.298570   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:53:08.307396   77024 logs.go:274] 0 containers: []
W0111 14:53:08.307403   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:53:08.307484   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:53:08.315635   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:53:08.315713   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:53:08.322830   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:53:08.322840   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:53:08.322843   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:53:08.347978   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:53:08.347986   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:53:08.361454   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:53:08.361470   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:53:08.372964   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:53:08.372970   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:53:08.387615   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:53:08.387624   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:53:08.396927   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:53:08.396938   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:53:08.406053   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:53:08.406058   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:53:08.418319   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:53:08.418324   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:53:08.427437   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:53:08.427443   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:53:08.436157   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:53:08.436163   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:53:08.468063   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:53:08.468069   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:53:08.472507   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:53:08.472513   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:53:08.520965   77024 logs.go:123] Gathering logs for container status ...
I0111 14:53:08.520973   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:53:11.039833   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:53:16.044020   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:53:16.044447   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-apiserver --format={{.ID}}
I0111 14:53:16.070983   77024 logs.go:274] 1 containers: [eb51f7bf5bbe]
I0111 14:53:16.071259   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_etcd --format={{.ID}}
I0111 14:53:16.087549   77024 logs.go:274] 1 containers: [d769be774868]
I0111 14:53:16.087675   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_coredns --format={{.ID}}
I0111 14:53:16.097747   77024 logs.go:274] 2 containers: [2ff32e8afcf3 8c1efbfecbf1]
I0111 14:53:16.097826   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-scheduler --format={{.ID}}
I0111 14:53:16.107967   77024 logs.go:274] 1 containers: [991a2f27a2f9]
I0111 14:53:16.108058   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-proxy --format={{.ID}}
I0111 14:53:16.122678   77024 logs.go:274] 1 containers: [0ad38c8ef363]
I0111 14:53:16.122782   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format={{.ID}}
I0111 14:53:16.130974   77024 logs.go:274] 0 containers: []
W0111 14:53:16.130979   77024 logs.go:276] No container was found matching "kubernetes-dashboard"
I0111 14:53:16.131059   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_storage-provisioner --format={{.ID}}
I0111 14:53:16.138893   77024 logs.go:274] 1 containers: [db6abde80912]
I0111 14:53:16.138967   77024 ssh_runner.go:195] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format={{.ID}}
I0111 14:53:16.146942   77024 logs.go:274] 1 containers: [eb3481b28ddd]
I0111 14:53:16.146951   77024 logs.go:123] Gathering logs for kube-apiserver [eb51f7bf5bbe] ...
I0111 14:53:16.146954   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb51f7bf5bbe"
I0111 14:53:16.159068   77024 logs.go:123] Gathering logs for etcd [d769be774868] ...
I0111 14:53:16.159074   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 d769be774868"
I0111 14:53:16.170479   77024 logs.go:123] Gathering logs for coredns [2ff32e8afcf3] ...
I0111 14:53:16.170489   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 2ff32e8afcf3"
I0111 14:53:16.179376   77024 logs.go:123] Gathering logs for kube-scheduler [991a2f27a2f9] ...
I0111 14:53:16.179381   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 991a2f27a2f9"
I0111 14:53:16.192202   77024 logs.go:123] Gathering logs for kube-proxy [0ad38c8ef363] ...
I0111 14:53:16.192207   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 0ad38c8ef363"
I0111 14:53:16.201523   77024 logs.go:123] Gathering logs for Docker ...
I0111 14:53:16.201529   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
I0111 14:53:16.228888   77024 logs.go:123] Gathering logs for dmesg ...
I0111 14:53:16.228897   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
I0111 14:53:16.234038   77024 logs.go:123] Gathering logs for describe nodes ...
I0111 14:53:16.234043   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.25.3/kubectl describe nodes --kubeconfig=/var/lib/minikube/kubeconfig"
I0111 14:53:16.275905   77024 logs.go:123] Gathering logs for coredns [8c1efbfecbf1] ...
I0111 14:53:16.275912   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 8c1efbfecbf1"
I0111 14:53:16.284752   77024 logs.go:123] Gathering logs for storage-provisioner [db6abde80912] ...
I0111 14:53:16.284759   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 db6abde80912"
I0111 14:53:16.294274   77024 logs.go:123] Gathering logs for kube-controller-manager [eb3481b28ddd] ...
I0111 14:53:16.294281   77024 ssh_runner.go:195] Run: /bin/bash -c "docker logs --tail 400 eb3481b28ddd"
I0111 14:53:16.308920   77024 logs.go:123] Gathering logs for container status ...
I0111 14:53:16.308928   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo `which crictl || echo crictl` ps -a || sudo docker ps -a"
I0111 14:53:16.322715   77024 logs.go:123] Gathering logs for kubelet ...
I0111 14:53:16.322722   77024 ssh_runner.go:195] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
I0111 14:53:18.855851   77024 api_server.go:252] Checking apiserver healthz at https://10.0.2.15:8443/healthz ...
I0111 14:53:23.858201   77024 api_server.go:268] stopped: https://10.0.2.15:8443/healthz: Get "https://10.0.2.15:8443/healthz": context deadline exceeded (Client.Timeout exceeded while awaiting headers)
I0111 14:53:23.874833   77024 out.go:177] 
W0111 14:53:23.880761   77024 out.go:239] ‚ùå  Exiting due to GUEST_START: wait 6m0s for node: wait for healthy API server: apiserver healthz never reported healthy: timed out waiting for the condition
W0111 14:53:23.880808   77024 out.go:239] 
W0111 14:53:23.884093   77024 out.go:239] [31m‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m    üòø  If the above advice does not help, please let us know:                             [31m‚îÇ[0m
[31m‚îÇ[0m    üëâ  https://github.com/kubernetes/minikube/issues/new/choose                           [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚îÇ[0m    Please run `minikube logs --file=logs.txt` and attach logs.txt to the GitHub issue.    [31m‚îÇ[0m
[31m‚îÇ[0m                                                                                           [31m‚îÇ[0m
[31m‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ[0m
I0111 14:53:23.896249   77024 out.go:177] 

* 
* ==> Docker <==
* -- Journal begins at Wed 2023-01-11 19:41:29 UTC, ends at Wed 2023-01-11 19:56:04 UTC. --
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.170138178Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.170273879Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.170298669Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.170385998Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/b1205c8ef5e32feefe90a33b47b9fe880fdaff359665dbca5ce2044615a5158a pid=11141 runtime=io.containerd.runc.v2
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.172607300Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.172628341Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.172632674Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.172746334Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/4a62a931ec9d8e69903bd90779d31fac7e6acc794e149d26c207c2b17d8149d4 pid=11177 runtime=io.containerd.runc.v2
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.174145179Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.174198093Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.174203176Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.174341252Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/f31eebf7f7af38d8e5bc3173efd492c1dc5203fde3dbe1044a3a96bd126fc060 pid=11179 runtime=io.containerd.runc.v2
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.373050721Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.373155133Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.373179256Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.373255586Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/eb51f7bf5bbe45222627a89cbc1dbdffdc815676094a76153d5d42d495d26382 pid=11298 runtime=io.containerd.runc.v2
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.442342803Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.442429632Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.442440173Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.442508253Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/eb3481b28ddd05b8a5491d221286f5b9ae8757fe535d2f1656080cae3e328070 pid=11353 runtime=io.containerd.runc.v2
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.443581406Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.443622570Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.443632736Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.443688817Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/991a2f27a2f9e1cd0368c594c53a6366289d38e61a4d0141dd795f579e193f59 pid=11349 runtime=io.containerd.runc.v2
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.490833128Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.490878875Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.490888417Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:45:56 minikube dockerd[709]: time="2023-01-11T19:45:56.490941580Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/d769be774868b105a26023fa841a80a262a2a8f8efa591b535fe710ceb0d4ea8 pid=11415 runtime=io.containerd.runc.v2
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.113684037Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.113758535Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.113770910Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.113824408Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/ca6f23f22ecd09bf6de99742a6ff87a771f380beb3d035f34dcb3658b380211f pid=11800 runtime=io.containerd.runc.v2
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.126906931Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.126940388Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.127040802Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.127131342Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/a748d1af0c889a920f5eb24d8444f01929774fbcc28917be873a1e9f6d714f5c pid=11830 runtime=io.containerd.runc.v2
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.386319197Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.386420736Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.386547816Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.386693437Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/8c1efbfecbf15e1b503367eaed1c7bc7f436431321ca51fd8ad8713f748763fc pid=11913 runtime=io.containerd.runc.v2
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.461421550Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.461458257Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.461463465Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.461645127Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/2ff32e8afcf3eb47605d1ab8ecf477d88fa052783b1a7ebea1d7adf1a9da6405 pid=11964 runtime=io.containerd.runc.v2
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.616183383Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.616219424Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.616238298Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.616295047Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/b12ddbdd559680011b31b9356425160e3e86e5ade573aff08727ecff17ba3345 pid=12014 runtime=io.containerd.runc.v2
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.686117584Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.686158416Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.686309537Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:46:15 minikube dockerd[709]: time="2023-01-11T19:46:15.686444117Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/0ad38c8ef363d60111d555a996cfc64d945d11ecb2421427cf035e0921227554 pid=12057 runtime=io.containerd.runc.v2
Jan 11 19:49:05 minikube dockerd[709]: time="2023-01-11T19:49:05.140092389Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:49:05 minikube dockerd[709]: time="2023-01-11T19:49:05.140138599Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:49:05 minikube dockerd[709]: time="2023-01-11T19:49:05.140144266Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:49:05 minikube dockerd[709]: time="2023-01-11T19:49:05.140639160Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/79ad2bcde0e9635503db5f160caf78f5736af017668c2cc7777ea4fa495d1660 pid=13378 runtime=io.containerd.runc.v2
Jan 11 19:49:05 minikube dockerd[709]: time="2023-01-11T19:49:05.290842233Z" level=info msg="loading plugin \"io.containerd.event.v1.publisher\"..." runtime=io.containerd.runc.v2 type=io.containerd.event.v1
Jan 11 19:49:05 minikube dockerd[709]: time="2023-01-11T19:49:05.290949028Z" level=info msg="loading plugin \"io.containerd.internal.v1.shutdown\"..." runtime=io.containerd.runc.v2 type=io.containerd.internal.v1
Jan 11 19:49:05 minikube dockerd[709]: time="2023-01-11T19:49:05.290975946Z" level=info msg="loading plugin \"io.containerd.ttrpc.v1.task\"..." runtime=io.containerd.runc.v2 type=io.containerd.ttrpc.v1
Jan 11 19:49:05 minikube dockerd[709]: time="2023-01-11T19:49:05.291051532Z" level=info msg="starting signal loop" namespace=moby path=/run/docker/containerd/daemon/io.containerd.runtime.v2.task/moby/db6abde80912e588c55aa5c63e3f2c3487934b9b7c0f5144b4b5f19baf153c1a pid=13426 runtime=io.containerd.runc.v2

* 
* ==> container status <==
* CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID
db6abde80912e       ba04bb24b9575       6 minutes ago       Running             storage-provisioner       0                   79ad2bcde0e96
0ad38c8ef363d       bcc74496abfdb       9 minutes ago       Running             kube-proxy                0                   b12ddbdd55968
2ff32e8afcf3e       b19406328e70d       9 minutes ago       Running             coredns                   0                   a748d1af0c889
8c1efbfecbf15       b19406328e70d       9 minutes ago       Running             coredns                   0                   ca6f23f22ecd0
d769be774868b       8e041a3b0ba8b       10 minutes ago      Running             etcd                      0                   4a62a931ec9d8
991a2f27a2f9e       13b15fc3e0938       10 minutes ago      Running             kube-scheduler            0                   f31eebf7f7af3
eb3481b28ddd0       cf6c9e4e18a33       10 minutes ago      Running             kube-controller-manager   0                   b1205c8ef5e32
eb51f7bf5bbe4       12dd70322f973       10 minutes ago      Running             kube-apiserver            0                   029aee1ac4228

* 
* ==> coredns [2ff32e8afcf3] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = 591cf328cccc12bc490481273e738df59329c62c0b729d94e8b61db9961c2fa5f046dd37f1cf888b953814040d180f52594972691cd6ff41be96639138a43908
CoreDNS-1.9.3
linux/arm64, go1.18.2, 45b0a11
[INFO] Reloading
[INFO] plugin/health: Going into lameduck mode for 5s
[INFO] plugin/reload: Running configuration SHA512 = 84fcbbc0d1ff363823d1d1e91939cc61825f344f54194ad4bb80778475b63b6dea2340419b295109186ac64dd150e1af0ea93d82083b769f60040d224f078540
[INFO] Reloading complete

* 
* ==> coredns [8c1efbfecbf1] <==
* .:53
[INFO] plugin/reload: Running configuration SHA512 = 591cf328cccc12bc490481273e738df59329c62c0b729d94e8b61db9961c2fa5f046dd37f1cf888b953814040d180f52594972691cd6ff41be96639138a43908
CoreDNS-1.9.3
linux/arm64, go1.18.2, 45b0a11
[INFO] Reloading
[INFO] plugin/health: Going into lameduck mode for 5s
[INFO] plugin/reload: Running configuration SHA512 = 84fcbbc0d1ff363823d1d1e91939cc61825f344f54194ad4bb80778475b63b6dea2340419b295109186ac64dd150e1af0ea93d82083b769f60040d224f078540
[INFO] Reloading complete

* 
* ==> describe nodes <==
* Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=arm64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=arm64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=986b1ebd987211ed16f8cc10aed7d2c42fc8392f
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2023_01_11T14_46_01_0700
                    minikube.k8s.io/version=v1.28.0
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    node.alpha.kubernetes.io/ttl: 0
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Wed, 11 Jan 2023 19:45:59 +0000
Taints:             <none>
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Wed, 11 Jan 2023 19:56:03 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Wed, 11 Jan 2023 19:51:08 +0000   Wed, 11 Jan 2023 19:45:57 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Wed, 11 Jan 2023 19:51:08 +0000   Wed, 11 Jan 2023 19:45:57 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Wed, 11 Jan 2023 19:51:08 +0000   Wed, 11 Jan 2023 19:45:57 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Wed, 11 Jan 2023 19:51:08 +0000   Wed, 11 Jan 2023 19:46:01 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  10.0.2.15
  Hostname:    minikube
Capacity:
  cpu:                2
  ephemeral-storage:  17784760Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             3905972Ki
  pods:               110
Allocatable:
  cpu:                2
  ephemeral-storage:  17784760Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  hugepages-32Mi:     0
  hugepages-64Ki:     0
  memory:             3905972Ki
  pods:               110
System Info:
  Machine ID:                 ea5ff82c23ac449493b84c372f8b24cf
  System UUID:                ea5ff82c23ac449493b84c372f8b24cf
  Boot ID:                    6c3682c7-be8c-49d9-82a3-e26989b22a4b
  Kernel Version:             5.10.57
  OS Image:                   Buildroot 2021.02.12
  Operating System:           linux
  Architecture:               arm64
  Container Runtime Version:  docker://20.10.20
  Kubelet Version:            v1.25.3
  Kube-Proxy Version:         v1.25.3
PodCIDR:                      10.244.0.0/24
PodCIDRs:                     10.244.0.0/24
Non-terminated Pods:          (8 in total)
  Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                ------------  ----------  ---------------  -------------  ---
  kube-system                 coredns-565d847f94-cdjsn            100m (5%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     9m50s
  kube-system                 coredns-565d847f94-mm8d6            100m (5%!)(MISSING)     0 (0%!)(MISSING)      70Mi (1%!)(MISSING)        170Mi (4%!)(MISSING)     9m50s
  kube-system                 etcd-minikube                       100m (5%!)(MISSING)     0 (0%!)(MISSING)      100Mi (2%!)(MISSING)       0 (0%!)(MISSING)         10m
  kube-system                 kube-apiserver-minikube             250m (12%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10m
  kube-system                 kube-controller-manager-minikube    200m (10%!)(MISSING)    0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10m
  kube-system                 kube-proxy-dvr6g                    0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         9m50s
  kube-system                 kube-scheduler-minikube             100m (5%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         10m
  kube-system                 storage-provisioner                 0 (0%!)(MISSING)        0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         7m
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                850m (42%!)(MISSING)  0 (0%!)(MISSING)
  memory             240Mi (6%!)(MISSING)  340Mi (8%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-32Mi     0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-64Ki     0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age    From             Message
  ----    ------                   ----   ----             -------
  Normal  Starting                 9m49s  kube-proxy       
  Normal  Starting                 10m    kubelet          Starting kubelet.
  Normal  NodeAllocatableEnforced  10m    kubelet          Updated Node Allocatable limit across pods
  Normal  NodeHasSufficientMemory  10m    kubelet          Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    10m    kubelet          Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     10m    kubelet          Node minikube status is now: NodeHasSufficientPID
  Normal  NodeReady                10m    kubelet          Node minikube status is now: NodeReady
  Normal  RegisteredNode           9m50s  node-controller  Node minikube event: Registered Node minikube in Controller

* 
* ==> dmesg <==
* [Jan11 19:41] ACPI: SRAT not present
[  +0.000000] KASLR disabled due to lack of seed
[  +0.775764] EINJ: EINJ table not found.
[  +0.772611] systemd-fstab-generator[114]: Ignoring "noauto" for root device
[  +0.044448] systemd[1]: systemd-journald.service: unit configures an IP firewall, but the local system does not support BPF/cgroup firewalling.
[  +0.000966] systemd[1]: (This warning is only shown for the first unit using IP firewalling.)
[ +10.076760] systemd-fstab-generator[462]: Ignoring "noauto" for root device
[  +0.083468] systemd-fstab-generator[473]: Ignoring "noauto" for root device
[  +0.702877] systemd-fstab-generator[673]: Ignoring "noauto" for root device
[  +0.085220] systemd-fstab-generator[684]: Ignoring "noauto" for root device
[  +0.074682] systemd-fstab-generator[695]: Ignoring "noauto" for root device
[  +1.280434] systemd-fstab-generator[860]: Ignoring "noauto" for root device
[  +0.081990] systemd-fstab-generator[871]: Ignoring "noauto" for root device
[  +4.234578] systemd-fstab-generator[1107]: Ignoring "noauto" for root device
[  +0.280002] kauditd_printk_skb: 67 callbacks suppressed
[  +5.240299] kauditd_printk_skb: 11 callbacks suppressed
[Jan11 19:42] kauditd_printk_skb: 14 callbacks suppressed
[ +31.799641] hrtimer: interrupt took 57384548 ns
[Jan11 19:45] systemd-fstab-generator[10987]: Ignoring "noauto" for root device
[Jan11 19:46] systemd-fstab-generator[11587]: Ignoring "noauto" for root device

* 
* ==> etcd [d769be774868] <==
* {"level":"warn","ts":"2023-01-11T19:45:56.821Z","caller":"flags/flag.go:93","msg":"unrecognized environment variable","environment-variable":"ETCD_UNSUPPORTED_ARCH=arm64"}
{"level":"info","ts":"2023-01-11T19:45:56.821Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://10.0.2.15:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--experimental-watch-progress-notify-interval=5s","--initial-advertise-peer-urls=https://10.0.2.15:2380","--initial-cluster=minikube=https://10.0.2.15:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://10.0.2.15:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://10.0.2.15:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2023-01-11T19:45:56.821Z","caller":"embed/etcd.go:131","msg":"configuring peer listeners","listen-peer-urls":["https://10.0.2.15:2380"]}
{"level":"info","ts":"2023-01-11T19:45:56.821Z","caller":"embed/etcd.go:479","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-01-11T19:45:56.821Z","caller":"embed/etcd.go:139","msg":"configuring client listeners","listen-client-urls":["https://10.0.2.15:2379","https://127.0.0.1:2379"]}
{"level":"info","ts":"2023-01-11T19:45:56.821Z","caller":"embed/etcd.go:308","msg":"starting an etcd server","etcd-version":"3.5.4","git-sha":"08407ff76","go-version":"go1.16.2","go-os":"linux","go-arch":"arm64","max-cpu-set":2,"max-cpu-available":2,"member-initialized":false,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://10.0.2.15:2380"],"listen-peer-urls":["https://10.0.2.15:2380"],"advertise-client-urls":["https://10.0.2.15:2379"],"listen-client-urls":["https://10.0.2.15:2379","https://127.0.0.1:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"minikube=https://10.0.2.15:2380","initial-cluster-state":"new","initial-cluster-token":"etcd-cluster","quota-size-bytes":2147483648,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2023-01-11T19:45:56.828Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"6.800523ms"}
{"level":"info","ts":"2023-01-11T19:45:56.852Z","caller":"etcdserver/raft.go:448","msg":"starting local member","local-member-id":"f074a195de705325","cluster-id":"ef296cf39f5d9d66"}
{"level":"info","ts":"2023-01-11T19:45:56.852Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 switched to configuration voters=()"}
{"level":"info","ts":"2023-01-11T19:45:56.852Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became follower at term 0"}
{"level":"info","ts":"2023-01-11T19:45:56.852Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft f074a195de705325 [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2023-01-11T19:45:56.852Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became follower at term 1"}
{"level":"info","ts":"2023-01-11T19:45:56.852Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 switched to configuration voters=(17326651331455243045)"}
{"level":"warn","ts":"2023-01-11T19:45:56.868Z","caller":"auth/store.go:1220","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2023-01-11T19:45:56.876Z","caller":"mvcc/kvstore.go:415","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2023-01-11T19:45:56.900Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2023-01-11T19:45:56.924Z","caller":"etcdserver/server.go:851","msg":"starting etcd server","local-member-id":"f074a195de705325","local-server-version":"3.5.4","cluster-version":"to_be_decided"}
{"level":"info","ts":"2023-01-11T19:45:56.925Z","caller":"etcdserver/server.go:736","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"f074a195de705325","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2023-01-11T19:45:56.933Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 switched to configuration voters=(17326651331455243045)"}
{"level":"info","ts":"2023-01-11T19:45:56.933Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"ef296cf39f5d9d66","local-member-id":"f074a195de705325","added-peer-id":"f074a195de705325","added-peer-peer-urls":["https://10.0.2.15:2380"]}
{"level":"info","ts":"2023-01-11T19:45:56.934Z","caller":"embed/etcd.go:688","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2023-01-11T19:45:56.934Z","caller":"embed/etcd.go:581","msg":"serving peer traffic","address":"10.0.2.15:2380"}
{"level":"info","ts":"2023-01-11T19:45:56.934Z","caller":"embed/etcd.go:553","msg":"cmux::serve","address":"10.0.2.15:2380"}
{"level":"info","ts":"2023-01-11T19:45:56.934Z","caller":"embed/etcd.go:277","msg":"now serving peer/client/metrics","local-member-id":"f074a195de705325","initial-advertise-peer-urls":["https://10.0.2.15:2380"],"listen-peer-urls":["https://10.0.2.15:2380"],"advertise-client-urls":["https://10.0.2.15:2379"],"listen-client-urls":["https://10.0.2.15:2379","https://127.0.0.1:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2023-01-11T19:45:56.934Z","caller":"embed/etcd.go:763","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2023-01-11T19:45:57.853Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 is starting a new election at term 1"}
{"level":"info","ts":"2023-01-11T19:45:57.853Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became pre-candidate at term 1"}
{"level":"info","ts":"2023-01-11T19:45:57.853Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 received MsgPreVoteResp from f074a195de705325 at term 1"}
{"level":"info","ts":"2023-01-11T19:45:57.853Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became candidate at term 2"}
{"level":"info","ts":"2023-01-11T19:45:57.853Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 received MsgVoteResp from f074a195de705325 at term 2"}
{"level":"info","ts":"2023-01-11T19:45:57.853Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"f074a195de705325 became leader at term 2"}
{"level":"info","ts":"2023-01-11T19:45:57.853Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: f074a195de705325 elected leader f074a195de705325 at term 2"}
{"level":"info","ts":"2023-01-11T19:45:57.853Z","caller":"etcdserver/server.go:2042","msg":"published local member to cluster through raft","local-member-id":"f074a195de705325","local-member-attributes":"{Name:minikube ClientURLs:[https://10.0.2.15:2379]}","request-path":"/0/members/f074a195de705325/attributes","cluster-id":"ef296cf39f5d9d66","publish-timeout":"7s"}
{"level":"info","ts":"2023-01-11T19:45:57.853Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-01-11T19:45:57.854Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"10.0.2.15:2379"}
{"level":"info","ts":"2023-01-11T19:45:57.854Z","caller":"etcdserver/server.go:2507","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2023-01-11T19:45:57.854Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2023-01-11T19:45:57.855Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"127.0.0.1:2379"}
{"level":"info","ts":"2023-01-11T19:45:57.856Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2023-01-11T19:45:57.856Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2023-01-11T19:45:57.867Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"ef296cf39f5d9d66","local-member-id":"f074a195de705325","cluster-version":"3.5"}
{"level":"info","ts":"2023-01-11T19:45:57.867Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2023-01-11T19:45:57.867Z","caller":"etcdserver/server.go:2531","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2023-01-11T19:55:57.880Z","caller":"mvcc/index.go:214","msg":"compact tree index","revision":493}
{"level":"info","ts":"2023-01-11T19:55:57.890Z","caller":"mvcc/kvstore_compaction.go:57","msg":"finished scheduled compaction","compact-revision":493,"took":"7.299963ms"}

* 
* ==> kernel <==
*  19:56:04 up 14 min,  0 users,  load average: 0.97, 0.65, 0.37
Linux minikube 5.10.57 #1 SMP PREEMPT Fri Oct 28 18:01:58 UTC 2022 aarch64 GNU/Linux
PRETTY_NAME="Buildroot 2021.02.12"

* 
* ==> kube-apiserver [eb51f7bf5bbe] <==
* W0111 19:45:58.229649       1 genericapiserver.go:656] Skipping API apps/v1beta1 because it has no resources.
W0111 19:45:58.230401       1 genericapiserver.go:656] Skipping API admissionregistration.k8s.io/v1beta1 because it has no resources.
W0111 19:45:58.231037       1 genericapiserver.go:656] Skipping API events.k8s.io/v1beta1 because it has no resources.
I0111 19:45:58.231471       1 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
I0111 19:45:58.231482       1 plugins.go:161] Loaded 11 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
W0111 19:45:58.241132       1 genericapiserver.go:656] Skipping API apiregistration.k8s.io/v1beta1 because it has no resources.
I0111 19:45:59.021995       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0111 19:45:59.022195       1 secure_serving.go:210] Serving securely on [::]:8443
I0111 19:45:59.022229       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/lib/minikube/certs/apiserver.crt::/var/lib/minikube/certs/apiserver.key"
I0111 19:45:59.036423       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0111 19:45:59.037934       1 apf_controller.go:300] Starting API Priority and Fairness config controller
I0111 19:45:59.037971       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I0111 19:45:59.038031       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0111 19:45:59.038638       1 available_controller.go:491] Starting AvailableConditionController
I0111 19:45:59.038674       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I0111 19:45:59.038732       1 controller.go:80] Starting OpenAPI V3 AggregationController
I0111 19:45:59.038847       1 customresource_discovery_controller.go:209] Starting DiscoveryController
I0111 19:45:59.039431       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I0111 19:45:59.039470       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0111 19:45:59.039530       1 autoregister_controller.go:141] Starting autoregister controller
I0111 19:45:59.039558       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0111 19:45:59.039877       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I0111 19:45:59.039905       1 shared_informer.go:255] Waiting for caches to sync for cluster_authentication_trust_controller
I0111 19:45:59.039987       1 controller.go:83] Starting OpenAPI AggregationController
I0111 19:45:59.040329       1 controller.go:85] Starting OpenAPI controller
I0111 19:45:59.040362       1 controller.go:85] Starting OpenAPI V3 controller
I0111 19:45:59.040395       1 naming_controller.go:291] Starting NamingConditionController
I0111 19:45:59.040437       1 establishing_controller.go:76] Starting EstablishingController
I0111 19:45:59.040472       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0111 19:45:59.040503       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0111 19:45:59.040593       1 crd_finalizer.go:266] Starting CRDFinalizer
I0111 19:45:59.042997       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I0111 19:45:59.043033       1 shared_informer.go:255] Waiting for caches to sync for crd-autoregister
I0111 19:45:59.043074       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0111 19:45:59.043250       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0111 19:45:59.087119       1 controller.go:616] quota admission added evaluator for: namespaces
I0111 19:45:59.133713       1 shared_informer.go:262] Caches are synced for node_authorizer
I0111 19:45:59.138845       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0111 19:45:59.138895       1 apf_controller.go:305] Running API Priority and Fairness config worker
I0111 19:45:59.140009       1 cache.go:39] Caches are synced for autoregister controller
I0111 19:45:59.140079       1 shared_informer.go:262] Caches are synced for cluster_authentication_trust_controller
I0111 19:45:59.140191       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0111 19:45:59.144577       1 shared_informer.go:262] Caches are synced for crd-autoregister
I0111 19:45:59.873306       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I0111 19:46:00.052231       1 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
I0111 19:46:00.059012       1 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
I0111 19:46:00.059033       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0111 19:46:00.254197       1 controller.go:616] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0111 19:46:00.266697       1 controller.go:616] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0111 19:46:00.298889       1 alloc.go:327] "allocated clusterIPs" service="default/kubernetes" clusterIPs=map[IPv4:10.96.0.1]
W0111 19:46:00.300955       1 lease.go:250] Resetting endpoints for master service "kubernetes" to [10.0.2.15]
I0111 19:46:00.301391       1 controller.go:616] quota admission added evaluator for: endpoints
I0111 19:46:00.302833       1 controller.go:616] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0111 19:46:01.081321       1 controller.go:616] quota admission added evaluator for: serviceaccounts
I0111 19:46:01.648365       1 controller.go:616] quota admission added evaluator for: deployments.apps
I0111 19:46:01.652384       1 alloc.go:327] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs=map[IPv4:10.96.0.10]
I0111 19:46:01.656464       1 controller.go:616] quota admission added evaluator for: daemonsets.apps
I0111 19:46:01.708338       1 controller.go:616] quota admission added evaluator for: leases.coordination.k8s.io
I0111 19:46:14.330680       1 controller.go:616] quota admission added evaluator for: replicasets.apps
I0111 19:46:14.934394       1 controller.go:616] quota admission added evaluator for: controllerrevisions.apps

* 
* ==> kube-controller-manager [eb3481b28ddd] <==
* I0111 19:46:14.302008       1 controllermanager.go:603] Started "bootstrapsigner"
I0111 19:46:14.302108       1 shared_informer.go:255] Waiting for caches to sync for bootstrap_signer
I0111 19:46:14.304338       1 controllermanager.go:603] Started "clusterrole-aggregation"
I0111 19:46:14.304507       1 clusterroleaggregation_controller.go:194] Starting ClusterRoleAggregator
I0111 19:46:14.304526       1 shared_informer.go:255] Waiting for caches to sync for ClusterRoleAggregator
I0111 19:46:14.306561       1 shared_informer.go:255] Waiting for caches to sync for resource quota
W0111 19:46:14.309342       1 actual_state_of_world.go:541] Failed to update statusUpdateNeeded field in actual state of world: Failed to set statusUpdateNeeded to needed true, because nodeName="minikube" does not exist
I0111 19:46:14.316911       1 shared_informer.go:262] Caches are synced for expand
I0111 19:46:14.319417       1 shared_informer.go:262] Caches are synced for crt configmap
I0111 19:46:14.321406       1 shared_informer.go:255] Waiting for caches to sync for garbage collector
I0111 19:46:14.325043       1 shared_informer.go:262] Caches are synced for deployment
I0111 19:46:14.327557       1 shared_informer.go:262] Caches are synced for stateful set
I0111 19:46:14.328451       1 shared_informer.go:262] Caches are synced for PVC protection
I0111 19:46:14.328498       1 shared_informer.go:262] Caches are synced for ReplicationController
I0111 19:46:14.328615       1 shared_informer.go:262] Caches are synced for PV protection
I0111 19:46:14.328665       1 shared_informer.go:262] Caches are synced for ephemeral
I0111 19:46:14.328720       1 shared_informer.go:262] Caches are synced for certificate-csrsigning-kubelet-serving
I0111 19:46:14.328750       1 shared_informer.go:262] Caches are synced for certificate-csrsigning-kubelet-client
I0111 19:46:14.328770       1 shared_informer.go:262] Caches are synced for certificate-csrsigning-kube-apiserver-client
I0111 19:46:14.328793       1 shared_informer.go:262] Caches are synced for certificate-csrsigning-legacy-unknown
I0111 19:46:14.329263       1 shared_informer.go:262] Caches are synced for persistent volume
I0111 19:46:14.334524       1 shared_informer.go:262] Caches are synced for certificate-csrapproving
I0111 19:46:14.335401       1 event.go:294] "Event occurred" object="kube-system/coredns" fieldPath="" kind="Deployment" apiVersion="apps/v1" type="Normal" reason="ScalingReplicaSet" message="Scaled up replica set coredns-565d847f94 to 2"
I0111 19:46:14.378959       1 shared_informer.go:262] Caches are synced for HPA
I0111 19:46:14.379079       1 shared_informer.go:262] Caches are synced for service account
I0111 19:46:14.378996       1 shared_informer.go:262] Caches are synced for endpoint_slice
I0111 19:46:14.379003       1 shared_informer.go:262] Caches are synced for endpoint_slice_mirroring
I0111 19:46:14.383223       1 shared_informer.go:262] Caches are synced for endpoint
I0111 19:46:14.383293       1 shared_informer.go:262] Caches are synced for namespace
I0111 19:46:14.386539       1 shared_informer.go:262] Caches are synced for node
I0111 19:46:14.386614       1 range_allocator.go:166] Starting range CIDR allocator
I0111 19:46:14.386639       1 shared_informer.go:255] Waiting for caches to sync for cidrallocator
I0111 19:46:14.386659       1 shared_informer.go:262] Caches are synced for cidrallocator
I0111 19:46:14.388313       1 shared_informer.go:262] Caches are synced for taint
I0111 19:46:14.388422       1 node_lifecycle_controller.go:1443] Initializing eviction metric for zone: 
W0111 19:46:14.388771       1 node_lifecycle_controller.go:1058] Missing timestamp for Node minikube. Assuming now as a timestamp.
I0111 19:46:14.388815       1 node_lifecycle_controller.go:1259] Controller detected that zone  is now in state Normal.
I0111 19:46:14.388646       1 taint_manager.go:204] "Starting NoExecuteTaintManager"
I0111 19:46:14.388934       1 taint_manager.go:209] "Sending events to api server"
I0111 19:46:14.388742       1 event.go:294] "Event occurred" object="minikube" fieldPath="" kind="Node" apiVersion="v1" type="Normal" reason="RegisteredNode" message="Node minikube event: Registered Node minikube in Controller"
I0111 19:46:14.391616       1 shared_informer.go:262] Caches are synced for attach detach
I0111 19:46:14.392075       1 range_allocator.go:367] Set node minikube PodCIDR to [10.244.0.0/24]
I0111 19:46:14.394950       1 shared_informer.go:262] Caches are synced for GC
I0111 19:46:14.397546       1 shared_informer.go:262] Caches are synced for ReplicaSet
I0111 19:46:14.399765       1 shared_informer.go:262] Caches are synced for TTL
I0111 19:46:14.402981       1 shared_informer.go:262] Caches are synced for bootstrap_signer
I0111 19:46:14.405194       1 shared_informer.go:262] Caches are synced for ClusterRoleAggregator
I0111 19:46:14.423589       1 shared_informer.go:262] Caches are synced for daemon sets
I0111 19:46:14.478923       1 shared_informer.go:262] Caches are synced for TTL after finished
I0111 19:46:14.512353       1 shared_informer.go:262] Caches are synced for job
I0111 19:46:14.529685       1 shared_informer.go:262] Caches are synced for cronjob
I0111 19:46:14.578616       1 shared_informer.go:262] Caches are synced for disruption
I0111 19:46:14.604165       1 shared_informer.go:262] Caches are synced for resource quota
I0111 19:46:14.607000       1 shared_informer.go:262] Caches are synced for resource quota
I0111 19:46:14.735816       1 event.go:294] "Event occurred" object="kube-system/coredns-565d847f94" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-565d847f94-mm8d6"
I0111 19:46:14.741240       1 event.go:294] "Event occurred" object="kube-system/coredns-565d847f94" fieldPath="" kind="ReplicaSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: coredns-565d847f94-cdjsn"
I0111 19:46:14.922524       1 shared_informer.go:262] Caches are synced for garbage collector
I0111 19:46:14.939124       1 event.go:294] "Event occurred" object="kube-system/kube-proxy" fieldPath="" kind="DaemonSet" apiVersion="apps/v1" type="Normal" reason="SuccessfulCreate" message="Created pod: kube-proxy-dvr6g"
I0111 19:46:14.979026       1 shared_informer.go:262] Caches are synced for garbage collector
I0111 19:46:14.979044       1 garbagecollector.go:163] Garbage collector: all resource monitors have synced. Proceeding to collect garbage

* 
* ==> kube-proxy [0ad38c8ef363] <==
* I0111 19:46:15.767714       1 node.go:163] Successfully retrieved node IP: 10.0.2.15
I0111 19:46:15.767784       1 server_others.go:138] "Detected node IP" address="10.0.2.15"
I0111 19:46:15.767821       1 server_others.go:578] "Unknown proxy mode, assuming iptables proxy" proxyMode=""
I0111 19:46:15.784889       1 server_others.go:199] "kube-proxy running in single-stack mode, this ipFamily is not supported" ipFamily=IPv6
I0111 19:46:15.784908       1 server_others.go:206] "Using iptables Proxier"
I0111 19:46:15.784946       1 proxier.go:262] "Setting route_localnet=1, use nodePortAddresses to filter loopback addresses for NodePorts to skip it https://issues.k8s.io/90259"
I0111 19:46:15.785140       1 server.go:661] "Version info" version="v1.25.3"
I0111 19:46:15.785145       1 server.go:663] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0111 19:46:15.785420       1 config.go:226] "Starting endpoint slice config controller"
I0111 19:46:15.785437       1 shared_informer.go:255] Waiting for caches to sync for endpoint slice config
I0111 19:46:15.785579       1 config.go:317] "Starting service config controller"
I0111 19:46:15.785582       1 shared_informer.go:255] Waiting for caches to sync for service config
I0111 19:46:15.785884       1 config.go:444] "Starting node config controller"
I0111 19:46:15.785887       1 shared_informer.go:255] Waiting for caches to sync for node config
I0111 19:46:15.886442       1 shared_informer.go:262] Caches are synced for node config
I0111 19:46:15.886450       1 shared_informer.go:262] Caches are synced for endpoint slice config
I0111 19:46:15.886485       1 shared_informer.go:262] Caches are synced for service config

* 
* ==> kube-scheduler [991a2f27a2f9] <==
* I0111 19:45:57.256345       1 serving.go:348] Generated self-signed cert in-memory
W0111 19:45:59.068878       1 requestheader_controller.go:193] Unable to get configmap/extension-apiserver-authentication in kube-system.  Usually fixed by 'kubectl create rolebinding -n kube-system ROLEBINDING_NAME --role=extension-apiserver-authentication-reader --serviceaccount=YOUR_NS:YOUR_SA'
W0111 19:45:59.069020       1 authentication.go:346] Error looking up in-cluster authentication configuration: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot get resource "configmaps" in API group "" in the namespace "kube-system"
W0111 19:45:59.069046       1 authentication.go:347] Continuing without authentication configuration. This may treat all requests as anonymous.
W0111 19:45:59.069077       1 authentication.go:348] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0111 19:45:59.082676       1 server.go:148] "Starting Kubernetes Scheduler" version="v1.25.3"
I0111 19:45:59.082705       1 server.go:150] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0111 19:45:59.083344       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I0111 19:45:59.083450       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0111 19:45:59.083470       1 shared_informer.go:255] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0111 19:45:59.083482       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
W0111 19:45:59.098831       1 reflector.go:424] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0111 19:45:59.098926       1 reflector.go:140] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0111 19:45:59.099027       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0111 19:45:59.099043       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0111 19:45:59.099097       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0111 19:45:59.099112       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0111 19:45:59.099150       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0111 19:45:59.099164       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0111 19:45:59.099188       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0111 19:45:59.099211       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0111 19:45:59.099255       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0111 19:45:59.099273       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0111 19:45:59.099300       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0111 19:45:59.099325       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0111 19:45:59.099351       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0111 19:45:59.099370       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0111 19:45:59.099415       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0111 19:45:59.099427       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0111 19:45:59.099453       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0111 19:45:59.099484       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0111 19:45:59.099513       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0111 19:45:59.099522       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0111 19:45:59.099545       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0111 19:45:59.099585       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0111 19:45:59.099609       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0111 19:45:59.099628       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0111 19:45:59.099663       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0111 19:45:59.099682       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0111 19:45:59.099699       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0111 19:45:59.099714       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0111 19:46:00.005995       1 reflector.go:424] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0111 19:46:00.006039       1 reflector.go:140] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0111 19:46:00.065760       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0111 19:46:00.065929       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0111 19:46:00.084983       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0111 19:46:00.085046       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0111 19:46:00.108038       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0111 19:46:00.108067       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0111 19:46:00.149650       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0111 19:46:00.149773       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0111 19:46:00.185797       1 reflector.go:424] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0111 19:46:00.185824       1 reflector.go:140] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
I0111 19:46:02.084472       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file

* 
* ==> kubelet <==
* -- Journal begins at Wed 2023-01-11 19:41:29 UTC, ends at Wed 2023-01-11 19:56:05 UTC. --
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.743026   11593 manager.go:447] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.743130   11593 plugin_manager.go:118] "Starting Kubelet Plugin Manager"
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.744382   11593 kubelet_network_linux.go:63] "Initialized iptables rules." protocol=IPv4
Jan 11 19:46:01 minikube kubelet[11593]: E0111 19:46:01.746685   11593 kubelet_network_linux.go:141] "Failed to ensure that KUBE-MARK-DROP chain exists" err=<
Jan 11 19:46:01 minikube kubelet[11593]:         error creating chain "KUBE-MARK-DROP": exit status 3: ip6tables v1.8.6 (legacy): can't initialize ip6tables table `nat': Table does not exist (do you need to insmod?)
Jan 11 19:46:01 minikube kubelet[11593]:         Perhaps ip6tables or your kernel needs to be upgraded.
Jan 11 19:46:01 minikube kubelet[11593]:  >
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.746701   11593 kubelet_network_linux.go:71] "Failed to initialize iptables rules; some functionality may be missing." protocol=IPv6
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.746706   11593 status_manager.go:161] "Starting to sync pod status with apiserver"
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.746716   11593 kubelet.go:2010] "Starting kubelet main sync loop"
Jan 11 19:46:01 minikube kubelet[11593]: E0111 19:46:01.746733   11593 kubelet.go:2034] "Skipping pod synchronization" err="PLEG is not healthy: pleg has yet to be successful"
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.809676   11593 kubelet_node_status.go:70] "Attempting to register node" node="minikube"
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.815247   11593 kubelet_node_status.go:108] "Node was previously registered" node="minikube"
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.815285   11593 kubelet_node_status.go:73] "Successfully registered node" node="minikube"
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.847063   11593 topology_manager.go:205] "Topology Admit Handler"
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.847144   11593 topology_manager.go:205] "Topology Admit Handler"
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.847164   11593 topology_manager.go:205] "Topology Admit Handler"
Jan 11 19:46:01 minikube kubelet[11593]: I0111 19:46:01.847691   11593 topology_manager.go:205] "Topology Admit Handler"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.006490   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/7e6ece94cd0950fdbbf66ddae1e4c53b-kubeconfig\") pod \"kube-scheduler-minikube\" (UID: \"7e6ece94cd0950fdbbf66ddae1e4c53b\") " pod="kube-system/kube-scheduler-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.006525   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/79b91f974a77634efcffb313d3a4b805-etcd-data\") pod \"etcd-minikube\" (UID: \"79b91f974a77634efcffb313d3a4b805\") " pod="kube-system/etcd-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.006535   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/c9066fa44c6f2e60c5c491458670db9c-ca-certs\") pod \"kube-apiserver-minikube\" (UID: \"c9066fa44c6f2e60c5c491458670db9c\") " pod="kube-system/kube-apiserver-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.006548   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/c9066fa44c6f2e60c5c491458670db9c-usr-share-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"c9066fa44c6f2e60c5c491458670db9c\") " pod="kube-system/kube-apiserver-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.006558   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/8ff82c85c8a8a0d667f0ac73853725cc-flexvolume-dir\") pod \"kube-controller-manager-minikube\" (UID: \"8ff82c85c8a8a0d667f0ac73853725cc\") " pod="kube-system/kube-controller-manager-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.006568   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/8ff82c85c8a8a0d667f0ac73853725cc-usr-share-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"8ff82c85c8a8a0d667f0ac73853725cc\") " pod="kube-system/kube-controller-manager-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.006584   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/79b91f974a77634efcffb313d3a4b805-etcd-certs\") pod \"etcd-minikube\" (UID: \"79b91f974a77634efcffb313d3a4b805\") " pod="kube-system/etcd-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.006594   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/c9066fa44c6f2e60c5c491458670db9c-k8s-certs\") pod \"kube-apiserver-minikube\" (UID: \"c9066fa44c6f2e60c5c491458670db9c\") " pod="kube-system/kube-apiserver-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.006606   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/8ff82c85c8a8a0d667f0ac73853725cc-ca-certs\") pod \"kube-controller-manager-minikube\" (UID: \"8ff82c85c8a8a0d667f0ac73853725cc\") " pod="kube-system/kube-controller-manager-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.006619   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/8ff82c85c8a8a0d667f0ac73853725cc-k8s-certs\") pod \"kube-controller-manager-minikube\" (UID: \"8ff82c85c8a8a0d667f0ac73853725cc\") " pod="kube-system/kube-controller-manager-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.006638   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/8ff82c85c8a8a0d667f0ac73853725cc-kubeconfig\") pod \"kube-controller-manager-minikube\" (UID: \"8ff82c85c8a8a0d667f0ac73853725cc\") " pod="kube-system/kube-controller-manager-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: E0111 19:46:02.086231   11593 kubelet.go:1712] "Failed creating a mirror pod for" err="pods \"kube-apiserver-minikube\" already exists" pod="kube-system/kube-apiserver-minikube"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.683193   11593 apiserver.go:52] "Watching apiserver"
Jan 11 19:46:02 minikube kubelet[11593]: I0111 19:46:02.911456   11593 reconciler.go:169] "Reconciler: start to sync state"
Jan 11 19:46:03 minikube kubelet[11593]: E0111 19:46:03.286850   11593 kubelet.go:1712] "Failed creating a mirror pod for" err="pods \"etcd-minikube\" already exists" pod="kube-system/etcd-minikube"
Jan 11 19:46:03 minikube kubelet[11593]: E0111 19:46:03.485586   11593 kubelet.go:1712] "Failed creating a mirror pod for" err="pods \"kube-scheduler-minikube\" already exists" pod="kube-system/kube-scheduler-minikube"
Jan 11 19:46:03 minikube kubelet[11593]: E0111 19:46:03.685803   11593 kubelet.go:1712] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-minikube\" already exists" pod="kube-system/kube-controller-manager-minikube"
Jan 11 19:46:03 minikube kubelet[11593]: I0111 19:46:03.752479   11593 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/f5b852c0-1cc6-4063-b601-77f7d57fd040/volumes"
Jan 11 19:46:03 minikube kubelet[11593]: I0111 19:46:03.752603   11593 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/a7546d95-323d-4d6b-ab8c-7bb335a928c2/volumes"
Jan 11 19:46:03 minikube kubelet[11593]: I0111 19:46:03.752620   11593 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/da49740b-2fd9-4d3d-938c-cb8c56517390/volumes"
Jan 11 19:46:03 minikube kubelet[11593]: I0111 19:46:03.752630   11593 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/0036d6c6-6d29-4192-9d07-ea78a54d55a6/volumes"
Jan 11 19:46:03 minikube kubelet[11593]: I0111 19:46:03.752637   11593 kubelet_getters.go:306] "Path does not exist" path="/var/lib/kubelet/pods/e9f5af41-234c-4c10-8a9e-45a25f70fa90/volumes"
Jan 11 19:46:03 minikube kubelet[11593]: I0111 19:46:03.883117   11593 request.go:682] Waited for 1.10760156s due to client-side throttling, not priority and fairness, request: POST:https://control-plane.minikube.internal:8443/api/v1/namespaces/kube-system/pods
Jan 11 19:46:03 minikube kubelet[11593]: E0111 19:46:03.885717   11593 kubelet.go:1712] "Failed creating a mirror pod for" err="pods \"kube-apiserver-minikube\" already exists" pod="kube-system/kube-apiserver-minikube"
Jan 11 19:46:14 minikube kubelet[11593]: I0111 19:46:14.480909   11593 kuberuntime_manager.go:1050] "Updating runtime config through cri with podcidr" CIDR="10.244.0.0/24"
Jan 11 19:46:14 minikube kubelet[11593]: I0111 19:46:14.481522   11593 kubelet_network.go:60] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.244.0.0/24"
Jan 11 19:46:14 minikube kubelet[11593]: I0111 19:46:14.741263   11593 topology_manager.go:205] "Topology Admit Handler"
Jan 11 19:46:14 minikube kubelet[11593]: I0111 19:46:14.755096   11593 topology_manager.go:205] "Topology Admit Handler"
Jan 11 19:46:14 minikube kubelet[11593]: I0111 19:46:14.882819   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-qdxls\" (UniqueName: \"kubernetes.io/projected/87b9dd96-bf6d-478c-91e1-3b4888d8052e-kube-api-access-qdxls\") pod \"coredns-565d847f94-mm8d6\" (UID: \"87b9dd96-bf6d-478c-91e1-3b4888d8052e\") " pod="kube-system/coredns-565d847f94-mm8d6"
Jan 11 19:46:14 minikube kubelet[11593]: I0111 19:46:14.882981   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/00714b6c-4386-447c-ab67-340465abc14e-config-volume\") pod \"coredns-565d847f94-cdjsn\" (UID: \"00714b6c-4386-447c-ab67-340465abc14e\") " pod="kube-system/coredns-565d847f94-cdjsn"
Jan 11 19:46:14 minikube kubelet[11593]: I0111 19:46:14.883066   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"config-volume\" (UniqueName: \"kubernetes.io/configmap/87b9dd96-bf6d-478c-91e1-3b4888d8052e-config-volume\") pod \"coredns-565d847f94-mm8d6\" (UID: \"87b9dd96-bf6d-478c-91e1-3b4888d8052e\") " pod="kube-system/coredns-565d847f94-mm8d6"
Jan 11 19:46:14 minikube kubelet[11593]: I0111 19:46:14.883083   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-zh4tv\" (UniqueName: \"kubernetes.io/projected/00714b6c-4386-447c-ab67-340465abc14e-kube-api-access-zh4tv\") pod \"coredns-565d847f94-cdjsn\" (UID: \"00714b6c-4386-447c-ab67-340465abc14e\") " pod="kube-system/coredns-565d847f94-cdjsn"
Jan 11 19:46:14 minikube kubelet[11593]: I0111 19:46:14.944380   11593 topology_manager.go:205] "Topology Admit Handler"
Jan 11 19:46:15 minikube kubelet[11593]: I0111 19:46:15.084672   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-proxy\" (UniqueName: \"kubernetes.io/configmap/5b473fb7-4ad9-448b-8e34-6ef80d263872-kube-proxy\") pod \"kube-proxy-dvr6g\" (UID: \"5b473fb7-4ad9-448b-8e34-6ef80d263872\") " pod="kube-system/kube-proxy-dvr6g"
Jan 11 19:46:15 minikube kubelet[11593]: I0111 19:46:15.084706   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-p2k8z\" (UniqueName: \"kubernetes.io/projected/5b473fb7-4ad9-448b-8e34-6ef80d263872-kube-api-access-p2k8z\") pod \"kube-proxy-dvr6g\" (UID: \"5b473fb7-4ad9-448b-8e34-6ef80d263872\") " pod="kube-system/kube-proxy-dvr6g"
Jan 11 19:46:15 minikube kubelet[11593]: I0111 19:46:15.084719   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"xtables-lock\" (UniqueName: \"kubernetes.io/host-path/5b473fb7-4ad9-448b-8e34-6ef80d263872-xtables-lock\") pod \"kube-proxy-dvr6g\" (UID: \"5b473fb7-4ad9-448b-8e34-6ef80d263872\") " pod="kube-system/kube-proxy-dvr6g"
Jan 11 19:46:15 minikube kubelet[11593]: I0111 19:46:15.084729   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"lib-modules\" (UniqueName: \"kubernetes.io/host-path/5b473fb7-4ad9-448b-8e34-6ef80d263872-lib-modules\") pod \"kube-proxy-dvr6g\" (UID: \"5b473fb7-4ad9-448b-8e34-6ef80d263872\") " pod="kube-system/kube-proxy-dvr6g"
Jan 11 19:49:04 minikube kubelet[11593]: I0111 19:49:04.777311   11593 topology_manager.go:205] "Topology Admit Handler"
Jan 11 19:49:04 minikube kubelet[11593]: I0111 19:49:04.906604   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-cgpnz\" (UniqueName: \"kubernetes.io/projected/9447c855-b2c7-452f-8ad7-29099f1e892e-kube-api-access-cgpnz\") pod \"storage-provisioner\" (UID: \"9447c855-b2c7-452f-8ad7-29099f1e892e\") " pod="kube-system/storage-provisioner"
Jan 11 19:49:04 minikube kubelet[11593]: I0111 19:49:04.906723   11593 reconciler.go:357] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tmp\" (UniqueName: \"kubernetes.io/host-path/9447c855-b2c7-452f-8ad7-29099f1e892e-tmp\") pod \"storage-provisioner\" (UID: \"9447c855-b2c7-452f-8ad7-29099f1e892e\") " pod="kube-system/storage-provisioner"
Jan 11 19:51:01 minikube kubelet[11593]: W0111 19:51:01.748037   11593 machine.go:65] Cannot read vendor id correctly, set empty.
Jan 11 19:56:01 minikube kubelet[11593]: W0111 19:56:01.740922   11593 machine.go:65] Cannot read vendor id correctly, set empty.

* 
* ==> storage-provisioner [db6abde80912] <==
* I0111 19:49:05.333335       1 storage_provisioner.go:116] Initializing the minikube storage provisioner...
I0111 19:49:05.338372       1 storage_provisioner.go:141] Storage provisioner initialized, now starting service!
I0111 19:49:05.338454       1 leaderelection.go:243] attempting to acquire leader lease kube-system/k8s.io-minikube-hostpath...
I0111 19:49:05.341960       1 leaderelection.go:253] successfully acquired lease kube-system/k8s.io-minikube-hostpath
I0111 19:49:05.342059       1 controller.go:835] Starting provisioner controller k8s.io/minikube-hostpath_minikube_4e3eeb32-7553-459b-8528-848b4c8e548a!
I0111 19:49:05.342708       1 event.go:282] Event(v1.ObjectReference{Kind:"Endpoints", Namespace:"kube-system", Name:"k8s.io-minikube-hostpath", UID:"5df6a1d6-be80-4fad-a329-fb83fae656e6", APIVersion:"v1", ResourceVersion:"412", FieldPath:""}): type: 'Normal' reason: 'LeaderElection' minikube_4e3eeb32-7553-459b-8528-848b4c8e548a became leader
I0111 19:49:05.443211       1 controller.go:884] Started provisioner controller k8s.io/minikube-hostpath_minikube_4e3eeb32-7553-459b-8528-848b4c8e548a!

